{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
<<<<<<< HEAD
      "provenance": [],
      "include_colab_link": true
=======
      "provenance": []
>>>>>>> upstream/main
    }
  },
  "cells": [
    {
<<<<<<< HEAD
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toddwalters/pgaiml-python-coding-examples/blob/main/deep-learning/C3/3_Linear_Regression_from_Scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
=======
>>>>>>> upstream/main
      "cell_type": "code",
      "metadata": {
        "id": "xid7Ggf0EhaO"
      },
      "source": [
        "\"\"\"\n",
        "Now lets build a Linear Regression Model from Scratch using the Tensorflow library\n",
        "\n",
        "Now, to build any machine learning model ,\n",
        "Most Importantly, we need to have: Data , Model , Loss Function , Criteria\n",
        "\n",
        "So, I will first generate the data set like this.\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gVXtqUPKEha9"
      },
      "source": [
        "import tensorflow as tf\n",
        "import random"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 1,
>>>>>>> upstream/main
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SPOFx68EEhbL"
      },
      "source": [
        "def Generate_Data(w, b, instances):\n",
        "    \"\"\"Generate y = Xw + b + noise.\"\"\"\n",
        "    X = tf.zeros((instances, w.shape[0]))\n",
        "    X += tf.random.normal(shape=X.shape)\n",
        "    y = tf.matmul(X, tf.reshape(w, (-1, 1))) + b\n",
        "    y += tf.random.normal(shape=y.shape, stddev=0.01) # Noise\n",
        "    y = tf.reshape(y, (-1, 1)) # Flattening\n",
        "    return X, y\n",
        "\n",
        "w_true = tf.constant([5.0,3.0]) # w1, w2\n",
        "b_true = 4.0\n",
        "features, labels = Generate_Data(w_true, b_true, 100)\n",
        "# (100,2) (100)"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 2,
>>>>>>> upstream/main
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fb9OqPfEhbZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d9241e-3715-4269-e16e-969442b9eb63"
      },
      "source": [
        "features.shape"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 3,
>>>>>>> upstream/main
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJIy2xBqEhbs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90066103-425c-4b46-9396-25a68cbfbc95"
      },
      "source": [
        "labels.shape"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 4,
>>>>>>> upstream/main
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([100, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oMtDl1dEhb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c5e6ea-4639-4a58-a6e9-3eedf8f7d309"
      },
      "source": [
        "features[0]"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 5,
>>>>>>> upstream/main
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.277386 ,  1.3770351], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z38zCPdrEhb8"
      },
      "source": [
        "#Model Parameters\n",
        "w = tf.Variable(tf.random.normal(shape=(w_true.shape[0], 1), mean=0, stddev=0.01),\n",
        "                trainable=True)\n",
        "b = tf.Variable(tf.zeros(1), trainable=True)"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 6,
>>>>>>> upstream/main
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTiGM4NrEhcC"
      },
      "source": [
        "w"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSvHQr6LEhcN"
      },
      "source": [
        "b"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVzUky08Ehcj"
      },
      "source": [
        "#Model\n",
        "def LR(X,w,b):\n",
        "    return tf.tensordot(X,w,axes=1) + b"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 7,
>>>>>>> upstream/main
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iapO-J6BEhcx"
      },
      "source": [
        "#Loss Function\n",
        "def Squared_Error(y_hat, y):\n",
        "    y = tf.reshape(y,y_hat.shape)\n",
        "    return ((y_hat - y) ** 2 )"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 8,
>>>>>>> upstream/main
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zy-zQLIWEhdA"
      },
      "source": [
        "#Learning Algorithm\n",
        "def Gradient_Descent(params,grads,lr):\n",
        "    for param,grad in zip(params,grads):\n",
        "        param -= lr*grad"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 9,
>>>>>>> upstream/main
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6bm9fP2EhdJ"
      },
      "source": [
        "lr = 0.02\n",
        "n = 3\n",
        "loss = Squared_Error\n",
        "\n",
        "for epoch in range(n):\n",
        "    for X, y in zip(features,labels):\n",
        "        with tf.GradientTape() as g:\n",
        "            l = loss(LR(X, w, b), y)  # loss(y_hat,y)\n",
        "\n",
        "        dw, db = g.gradient(l, [w, b]) # gradients\n",
        "\n",
        "        Gradient_Descent([w, b], [dw, db], lr) #Parameter Update\n",
        "    train_loss = loss(LR(features, w, b), labels)\n",
        "    print(f'epoch {epoch + 1}, loss {float(tf.reduce_mean(train_loss)):f}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Bsvr7rEhdS"
      },
      "source": [
        "https://www.tensorflow.org/api_docs/python/tf/Variable#:~:text=assign_sub,-View%20source&text=Subtracts%20a%20value%20from%20this%20variable.&text=read_value-,if%20True%2C%20will%20return%20something%20which%20evaluates%20to%20the%20new,will%20return%20the%20assign%20op."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsoklgItEhdT"
      },
      "source": [
        "#Learning Algorithm with momentum\n",
        "def Gradient_Descent(params,grads,lr):\n",
        "  beta = 0.6\n",
        "  m = beta*m - lr*grad\n",
        "  for param,grad in zip(params,grads):\n",
        "        param.assign_sub(m)\n",
        "    # for param,grad in zip(params,grads):\n",
        "    #     param.assign_sub(lr*grad) # param -= lr*grad"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 11,
>>>>>>> upstream/main
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mu-6Q54NEhdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "731f12b1-2717-4f76-c6c0-3db5cc57230d"
      },
      "source": [
        "lr = 0.02\n",
        "n = 10\n",
        "loss = Squared_Error\n",
        "\n",
        "for epoch in range(n):\n",
        "    for X, y in zip(features,labels):\n",
        "        with tf.GradientTape() as g:\n",
        "            l = loss(LR(X, w, b), y)\n",
        "\n",
        "        dw, db = g.gradient(l, [w, b]) # gradients\n",
        "\n",
        "        Gradient_Descent([w, b], [dw, db], lr) #Parameter Update\n",
        "    train_loss = loss(LR(features, w, b), labels)\n",
        "    print(f'epoch {epoch + 1}, loss {float(tf.reduce_mean(train_loss)):f}')"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 12,
>>>>>>> upstream/main
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.009633\n",
            "epoch 2, loss 0.000102\n",
            "epoch 3, loss 0.000103\n",
            "epoch 4, loss 0.000103\n",
            "epoch 5, loss 0.000103\n",
            "epoch 6, loss 0.000103\n",
            "epoch 7, loss 0.000103\n",
            "epoch 8, loss 0.000103\n",
            "epoch 9, loss 0.000103\n",
            "epoch 10, loss 0.000103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OxgPQ_HEhdp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a4773db-6676-44ca-e44c-389e4d2ac91b"
      },
      "source": [
        "w"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 13,
>>>>>>> upstream/main
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
              "array([[4.9981866],\n",
              "       [2.9992385]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjSwfxINEhdz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f81e11d6-2f53-441a-9cfe-f160193a25f4"
      },
      "source": [
        "b"
      ],
<<<<<<< HEAD
      "execution_count": null,
=======
      "execution_count": 14,
>>>>>>> upstream/main
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Variable 'Variable:0' shape=(1,) dtype=float32, numpy=array([4.0019574], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSXLWqMbEhd7"
      },
      "source": [
        "w_true,b_true"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Za47qDzGJlJH"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}