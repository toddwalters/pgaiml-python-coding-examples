{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toddwalters/pgaiml-python-coding-examples/blob/main/deep-learning/C8/12_06_Building_and_Visualizing_an_Autoencoder_with_the_Fashion_MNIST_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOQhF2KMWIdp"
      },
      "source": [
        "# __Building and Visualizing an Autoencoder with the Fashion MNIST Dataset__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnDyF-j2WIdw"
      },
      "source": [
        "Autoencoders are a special type of neural network used for:\n",
        "\n",
        "- Data compression\n",
        "- Feature extraction\n",
        "- Dimensionality reduction\n",
        "- Learning generative models of data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Steps to Be Followed\n",
        "1. Importing libraries\n",
        "2. Loading the dataset and finding the shape of the data\n",
        "3. Initializing the autoencoder\n",
        "4. Compiling the autoencoder\n",
        "5. Training the model\n",
        "6. Visualizing the images"
      ],
      "metadata": {
        "id": "BuB6nHmVr7vm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "xndySBmPWIdx"
      },
      "source": [
        "###Step 1: Importing Libraries\n",
        "- Import the required library such as NumPy, Pandas, TensorFlow,and Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KteOPBSWIdy"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "UCiO00Q0WId0"
      },
      "source": [
        "### Step 2: Loading the Dataset and Finding the Shape of the Data\n",
        "\n",
        "- Dataset used: Fashion MNSIT dataset where each image is 28 *28 pixels\n",
        "- Find the shape of the train and test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-o4rX184WId0",
        "outputId": "1f716963-7e68-496d-9235-3858884abaea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "(x_train, _), (x_test, _) = fashion_mnist.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "print (x_train.shape)\n",
        "print (x_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Observation:__\n",
        "- Here, the shape function retrieves the number of rows and columns present in the train and test data."
      ],
      "metadata": {
        "id": "YVJiLZavYx-K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kdg2ePgTWId2"
      },
      "source": [
        "### Step 3: Initializing the Autoencoder\n",
        "- Define the value of __latent_dim__ as __64__\n",
        "- Define a class called __Autoencoder__ that extends the __Model__ class from TensorFlow\n",
        "- Inside the Autoencoder class, define the constructor (__init__) that takes __latent_dim__ as a parameter\n",
        "- In the constructor, set __self.latent_dim__ to the value of __latent_dim__\n",
        "- Define the encoder part of the autoencoder using __tf.keras.Sequential__\n",
        "- In the encoder, flatten the input using __layers.Flatten()__\n",
        "- Add a dense layer to the encoder with latent_dim units and ReLU activation using __layers.Dense(latent_dim, activation='relu')__\n",
        "- Define the decoder part of the autoencoder using __tf.keras.Sequential__\n",
        "- In the decoder, add a dense layer with __784__ units and sigmoid activation using __layers.Dense(784, activation='sigmoid')__\n",
        "- Reshape the output of the dense layer to a 28x28 shape using __layers.Reshape((28, 28))__\n",
        "- Define the call method of the __Autoencoder__ class\n",
        "- Inside the call method, pass the input x through the encoder to obtain the encoded representation\n",
        "- Pass the encoded representation through the decoder to obtain the reconstructed output\n",
        "- Return the reconstructed output\n",
        "- Create an instance of the __Autoencoder__ class called autoencoder, passing the value of __latent_dim__ as an argument"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnI5ol-dWId3"
      },
      "outputs": [],
      "source": [
        "latent_dim = 64\n",
        "\n",
        "class Autoencoder(Model):\n",
        "  def __init__(self, latent_dim):\n",
        "    super(Autoencoder, self).__init__()\n",
        "    self.latent_dim = latent_dim\n",
        "    self.encoder = tf.keras.Sequential([\n",
        "      layers.Flatten(),\n",
        "      layers.Dense(latent_dim, activation='relu'),\n",
        "    ])\n",
        "    self.decoder = tf.keras.Sequential([\n",
        "      layers.Dense(784, activation='sigmoid'),\n",
        "      layers.Reshape((28, 28))\n",
        "    ])\n",
        "\n",
        "  def call(self, x):\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return decoded\n",
        "\n",
        "autoencoder = Autoencoder(latent_dim)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Observations:__\n",
        "- The code does not produce any output by itself. It defines a class and creates an instance of that class.\n",
        "- The output will depend on how the autoencoder model is trained and used further in the code."
      ],
      "metadata": {
        "id": "1AKrupUebYNP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Compiling the Autoencoder\n",
        "- Call the __compile()__ method on the autoencoder object.\n",
        "- Set the optimizer argument to __adam__. This specifies that the Adam optimizer will be used for training the autoencoder.\n",
        "- Set the loss argument to __losses.MeanSquaredError()__. This specifies that the mean squared error loss function will be used for training the autoencoder."
      ],
      "metadata": {
        "id": "1ODpG7WnbLkT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FF7eAXGqWId4"
      },
      "outputs": [],
      "source": [
        "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Observation:__\n",
        "- It configures the autoencoder model for training by setting the optimizer and loss function."
      ],
      "metadata": {
        "id": "OitKLTwJbpXU"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Y7Dla_hWId4"
      },
      "source": [
        "### Step 5: Training the Model\n",
        "- Call the __fit()__ method on the autoencoder object.\n",
        "- Pass __x_train__ as the first argument. x_train represents the input data for training the autoencoder.\n",
        "- Pass __x_train__ again as the second argument. This is the target data for the autoencoder, which is also x_train in this case.\n",
        "- Set the __epochs__ argument to __10__. This specifies the number of times the entire dataset will be iterated during training.\n",
        "- Set the __shuffle__ argument to __True__. This indicates that the training data will be shuffled before each epoch during training.\n",
        "- Set the validation_data argument to __(x_test, x_test)__. This provides the validation data to evaluate the performance of the autoencoder during training. x_test is the input validation data, and x_test is also used as the target validation data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Oi27ENdWId4",
        "outputId": "e682cd35-0fe4-4014-d6ca-d16d0798ba47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.0237 - val_loss: 0.0133\n",
            "Epoch 2/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0117 - val_loss: 0.0106\n",
            "Epoch 3/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0101 - val_loss: 0.0097\n",
            "Epoch 4/10\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0094 - val_loss: 0.0093\n",
            "Epoch 5/10\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.0091 - val_loss: 0.0091\n",
            "Epoch 6/10\n",
            "1354/1875 [====================>.........] - ETA: 1s - loss: 0.0090"
          ]
        }
      ],
      "source": [
        "autoencoder.fit(x_train, x_train,\n",
        "                epochs=10,\n",
        "                shuffle=True,\n",
        "                validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Observations:__\n",
        "- The __fit()__ method trains the autoencoder model on the provided data and produces output.\n",
        "- During training, it displays information such as the loss and metrics for each epoch, the progress bar, and validation metrics if validation data is provided.\n",
        "- The final output is the trained autoencoder model with updated weights."
      ],
      "metadata": {
        "id": "dX4XyfU6cndd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 6: Encoding and Decoding the Images\n",
        "- Call the encoder method of the autoencoder object on __x_test__. This encodes the input x_test using the trained autoencoder's encoder part.\n",
        "- Call the __numpy()__ method on the encoded output to convert it into a NumPy array.\n",
        "- This is done to extract the actual values from the TensorFlow tensor.\n",
        "- Assign the encoded output to the variable __encoded_imgs__.\n",
        "- Call the decoder method of the autoencoder object on encoded_imgs. This decodes the encoded images using the trained autoencoder's decoder part.\n",
        "- Call the numpy() method on the decoded output to convert it into a NumPy array.\n",
        "- Assign the decoded output to the variable __decoded_imgs__."
      ],
      "metadata": {
        "id": "RQOll3M5dh4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuX2iJQDWId5"
      },
      "outputs": [],
      "source": [
        "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
        "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 7: Displaying the Images\n",
        "\n",
        "- Set up the figure and subplot layout\n",
        "- Iterate through a range of n (in this case, 10) for displaying original and reconstructed images\n",
        "- Display the original image in the current subplot, along with the __original__ title and grayscale colormap\n",
        "- Display the reconstructed image in the next subplot, along with the __reconstructed__ title and grayscale colormap"
      ],
      "metadata": {
        "id": "rSTwoyvgeb6d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9NT0tzMPWId6"
      },
      "outputs": [],
      "source": [
        "n = 10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "\n",
        "  ax = plt.subplot(2, n, i + 1)\n",
        "  plt.imshow(x_test[i])\n",
        "  plt.title(\"original\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "\n",
        "  ax = plt.subplot(2, n, i + 1 + n)\n",
        "  plt.imshow(decoded_imgs[i])\n",
        "  plt.title(\"reconstructed\")\n",
        "  plt.gray()\n",
        "  ax.get_xaxis().set_visible(False)\n",
        "  ax.get_yaxis().set_visible(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "__Observations:__\n",
        "- The code generates a figure that showcases n original images alongside their corresponding reconstructed images, with the __original__ and __reconstructed__ titles.\n",
        "- The images are displayed in grayscale."
      ],
      "metadata": {
        "id": "9_m-QAxCeu4E"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}