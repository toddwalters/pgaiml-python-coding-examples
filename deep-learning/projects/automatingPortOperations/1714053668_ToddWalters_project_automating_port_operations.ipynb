{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TngvpkHUYxUK"
    "id": "TngvpkHUYxUK"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hlP3gKO0YnXm"
   },
   "source": [
    "# <a id='toc1_'></a>[**Automating Port Operations**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eshtNPMUYnXn"
   },
   "source": [
    "-----------------------------\n",
    "## <a id='toc1_1_'></a>[**Context**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "Marina Pier Inc. is leveraging technology to automate their operations on the San Francisco port.\n",
    "The companyâ€™s management has set out to build a bias-free/ corruption-free automatic system that reports & avoids faulty situations caused by human error.\n",
    "\n",
    "-----------------------------\n",
    "## <a id='toc1_2_'></a>[**Objectives**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "Marina Pier wants to use Deep Learning techniques to build an automatic reporting system that recognizes the boat. The company is also looking to use a transfer learning approach of any lightweight pre-trained model in order to deploy in mobile devices.\n",
    "As a deep learning engineer, your task is to:\n",
    "\n",
    "1.\tBuild a CNN network to classify the boat.\n",
    "\n",
    "2.\tBuild a lightweight model with the aim of deploying the solution on a mobile device using transfer learning. You can use any lightweight pre-trained model as the initial (first) layer. MobileNetV2 is a popular lightweight pre-trained model built using Keras API.\n",
    "\n",
    "-----------------------------\n",
    "## <a id='toc1_3_'></a>[**Dataset**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "**boat_type_classification_dataset.zip**\n",
    "\n",
    "The dataset contains images of 9 types of boats. It contains a total of 1162 images. The training images are provided in the directory of the specific class itself.\n",
    "Classes:\n",
    "\n",
    "- ferry_boat\n",
    "- gondola\n",
    "- sailboat\n",
    "- cruise_ship\n",
    "- kayak\n",
    "- inflatable_boat\n",
    "- paper_boat\n",
    "- buoy\n",
    "- freight_boat\n",
    "\n",
    "\n",
    "-----------------------------------\n",
    "## <a id='toc1_4_'></a>[**Analysis Steps to Perform**](#toc0_)\n",
    "-----------------------------------\n",
    "1.\tBuild a CNN network to classify the boat.\n",
    "\n",
    "    1.1.\tSplit the dataset into train and test in the ratio 80:20, with shuffle and random state=43.\n",
    "\n",
    "    1.2.\tUse tf.keras.preprocessing.image_dataset_from_directory to load the train and test datasets. This function also supports data normalization.*(Hint: image_scale=1./255)*\n",
    "\n",
    "    1.3.\tLoad train, validation and test dataset in batches of 32 using the function initialized in the above step.\n",
    "\n",
    "    1.4.\tBuild a CNN network using Keras with the following layers\n",
    "\n",
    "       - Cov2D with 32 filters, kernel size 3,3, and activation relu, followed by MaxPool2D\n",
    "\n",
    "       - Cov2D with 32 filters, kernel size 3,3, and activation relu, followed by MaxPool2D\n",
    "\n",
    "       - GLobalAveragePooling2D layer\n",
    "\n",
    "       - Dense layer with 128 neurons and activation relu\n",
    "\n",
    "       - Dense layer with 128 neurons and activation relu\n",
    "    \n",
    "       - Dense layer with 9 neurons and activation softmax.\n",
    "\n",
    "    1.5.\tCompile the model with Adam optimizer, categorical_crossentropy loss, and with metrics accuracy, precision, and recall.\n",
    "\n",
    "    1.6.\tTrain the model for 20 epochs and plot training loss and accuracy against epochs.\n",
    "\n",
    "    1.7.\tEvaluate the model on test images and print the test loss and accuracy.\n",
    "\n",
    "    1.8.\tPlot heatmap of the confusion matrix and print classification report.\n",
    "\n",
    "2.\tBuild a lightweight model with the aim of deploying the solution on a mobile device using transfer learning. You can use any lightweight pre-trained model as the initial (first) layer. MobileNetV2 is a popular lightweight pre-trained model built using Keras API.\n",
    "\n",
    "    2.1.\tSplit the dataset into train and test datasets in the ration 70:30, with shuffle and random state=1.\n",
    "\n",
    "    2.2.\tUse tf.keras.preprocessing.image_dataset_from_directory to load the train and test datasets. This function also supports data normalization.*(Hint: Image_scale=1./255)*\n",
    "\n",
    "    2.3.\tLoad train, validation and test datasets in batches of 32 using the function initialized in the above step.\n",
    "\n",
    "    2.4.\tBuild a CNN network using Keras with the following layers.\n",
    "\n",
    "      - Load MobileNetV2 - Light Model as the first layer *(Hint: Keras API Doc)*\n",
    "\n",
    "      - GLobalAveragePooling2D layer\n",
    "\n",
    "      - Dropout(0.2)\n",
    "\n",
    "      - Dense layer with 256 neurons and activation relu\n",
    "\n",
    "      - BatchNormalization layer\n",
    "\n",
    "      - Dropout(0.1)\n",
    "\n",
    "      - Dense layer with 128 neurons and activation relu\n",
    "\n",
    "      - BatchNormalization layer\n",
    "\n",
    "      - Dropout(0.1)\n",
    "\n",
    "      - Dense layer with 9 neurons and activation softmax\n",
    "\n",
    "    2.5.\tCompile the model with Adam optimizer, categorical_crossentropy loss, and metrics accuracy, Precision, and Recall.\n",
    "\n",
    "    2.6.\tTrain the model for 50 epochs and Early stopping while monitoring validation loss.\n",
    "\n",
    "    2.7.\tEvaluate the model on test images and print the test loss and accuracy.\n",
    "\n",
    "    2.8.\tPlot Train loss Vs Validation loss and Train accuracy Vs Validation accuracy.\n",
    "    \n",
    "3.\tCompare the results of both models built in steps 1 and 2 and state your observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dKqfUfK-QxGs"
   },
   "source": [
    "## <a id='toc1_5_'></a>[**1.0 Build A CNN Network To Classify A Boat**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DfnCMzofYnXo"
   },
   "source": [
    "**Setup: Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P4Hg3LX8YnXo"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C5s6OZ8zYnXp"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the path to your dataset\n",
    "#data_dir = pathlib.Path(\"boat_type_classification_dataset\")\n",
    "data_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/datasets/boat_type_classification_dataset\")\n",
    "\n",
    "# Set common parameters\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the path to your dataset\n",
    "#data_dir = pathlib.Path(\"boat_type_classification_dataset\")\n",
    "data_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/datasets/boat_type_classification_dataset\")\n",
    "\n",
    "# Set common parameters\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ViJnamSoYnXp"
   },
   "source": [
    "### <a id='toc1_5_1_'></a>[**1.1 Split the dataset into train and test in the ratio 80:20, with shuffle and random state=43**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhwPPUJnYnXp",
    "outputId": "d1f16c9f-56ec-4839-b07d-334ff9cbb20e"
    "outputId": "d1f16c9f-56ec-4839-b07d-334ff9cbb20e"
   },
   "outputs": [],
   "source": [
    "# Load and split the full dataset\n",
    "full_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=43,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=None,  # Load without batching initially\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Split the full dataset into train and test\n",
    "train_ds, test_ds = full_ds\n",
    "\n",
    "# Store class names\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "# Store class names\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"Number of training samples:\", tf.data.experimental.cardinality(train_ds))\n",
    "print(\"Number of test samples:\", tf.data.experimental.cardinality(test_ds))\n",
    "print(\"Class names:\", class_names)"
    "print(\"Number of test samples:\", tf.data.experimental.cardinality(test_ds))\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klAH8HCXYnXp"
   },
   "source": [
    "#### <a id='toc1_5_1_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.1** is responsible for loading the dataset and splitting it into training and testing sets.\n",
    "\n",
    "- We use `tf.keras.preprocessing.image_dataset_from_directory` to load images directly from the filesystem. This function is convenient as it handles the file reading and label assignment automatically.\n",
    "- We set `validation_split=0.2` and `subset=\"both\"` to get both training and testing sets in an 80:20 ratio.\n",
    "- `seed=43` ensures reproducibility of the random split.\n",
    "- `shuffle=True` randomizes the order of the samples, which is important for training neural networks.\n",
    "- We set `batch_size=batch_size` setting the batch size here means that our dataset will be divided into batches of 32 images each. This is important for several reasons:\n",
    "  - *Memory Efficiency:* Processing 32 images at a time is more memory-efficient than loading the entire dataset at once, especially for large datasets.\n",
    "  - *Training Dynamics:* Batch size affects the dynamics of model training. A batch size of 32 is often a good default, balancing between the noisy gradients of very small batches and the longer computation time of larger batches.\n",
    "  - *Consistency:* By setting the batch size here, we ensure that all parts of our pipeline (data loading, augmentation, model training) use the same batch size.\n",
    "- We set `batch_size=batch_size` setting the batch size here means that our dataset will be divided into batches of 32 images each. This is important for several reasons:\n",
    "  - *Memory Efficiency:* Processing 32 images at a time is more memory-efficient than loading the entire dataset at once, especially for large datasets.\n",
    "  - *Training Dynamics:* Batch size affects the dynamics of model training. A batch size of 32 is often a good default, balancing between the noisy gradients of very small batches and the longer computation time of larger batches.\n",
    "  - *Consistency:* By setting the batch size here, we ensure that all parts of our pipeline (data loading, augmentation, model training) use the same batch size.\n",
    "- The `image_size` parameter resizes all images to a consistent size, which is necessary for batch processing in neural networks.\n",
    "\n",
    "#### <a id='toc1_5_1_2_'></a>[Why it's important:](#toc0_)\n",
    "\n",
    "- Properly splitting the data ensures we have separate sets for training and evaluation, which is crucial for assessing the model's performance on unseen data.\n",
    "- The 80:20 split is a common ratio that balances having enough training data while still retaining a significant portion for testing.\n",
    "- Shuffling the data helps prevent any bias that might occur from the order of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DxrOw6tTYnXq"
   },
   "source": [
    "### <a id='toc1_5_2_'></a>[**1.2 Use tf.keras.preprocessing.image_dataset_from_directory to load the train and test datasets.**](#toc0_)\n",
    "\n",
    "This function also supports data normalization. *(Hint: image_scale=1./255)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2AfPaoaLYnXq",
    "outputId": "7ecf2101-fa60-4659-fc9b-009aef62c224"
    "outputId": "7ecf2101-fa60-4659-fc9b-009aef62c224"
   },
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "# Apply normalization to the datasets\n",
    "train_ds = train_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Function to check normalization\n",
    "# Function to check normalization\n",
    "def check_normalization(dataset):\n",
    "    for images, _ in dataset.take(1):\n",
    "        print(\"Image data range:\", tf.reduce_min(images).numpy(), \"to\", tf.reduce_max(images).numpy())\n",
    "        print(\"Image data range:\", tf.reduce_min(images).numpy(), \"to\", tf.reduce_max(images).numpy())\n",
    "\n",
    "print(\"Checking train dataset normalization:\")\n",
    "check_normalization(train_ds)\n",
    "check_normalization(train_ds)\n",
    "print(\"\\nChecking test dataset normalization:\")\n",
    "check_normalization(test_ds)"
    "check_normalization(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ABeSugwyYnXq"
   },
   "source": [
    "#### <a id='toc1_5_2_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.2** is performing the following:\n",
    "\n",
    "- Focuses on normalizing the image data and verifying that the normalization was applied correctly.\n",
    "- Defines a `normalize_img` function that converts the image data from integers in the range [0, 255] to floating-point numbers in the range [0, 1].\n",
    "- Applies this normalization to both the training and testing datasets using the map function.\n",
    "- The `check_normalization` function safely checks the range of values in the normalized datasets.\n",
    "\n",
    "#### <a id='toc1_5_2_2_'></a>[Why it's important](#toc0_)\n",
    "\n",
    "- Normalization is crucial for neural network training. It helps the model converge faster and can lead to better performance.\n",
    "- Scaling the input to a standard range (like [0, 1]) ensures that all features contribute equally to the model's learning process.\n",
    "- Checking the normalization helps verify that our preprocessing steps are working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipuvVlumYnXq"
   },
   "source": [
    "### <a id='toc1_5_3_'></a>[**1.3 Load train, validation and test dataset in batches of 32 using the function initialized in the above step.**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ojbcKWRhYnXq",
    "outputId": "db829227-92cc-4b72-f3d8-1c729d932925"
    "outputId": "db829227-92cc-4b72-f3d8-1c729d932925"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, is_training=False):\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    if is_training:\n",
    "        data_augmentation = tf.keras.Sequential([\n",
    "            tf.keras.layers.RandomFlip('horizontal'),\n",
    "            tf.keras.layers.RandomRotation(0.2),\n",
    "        ])\n",
    "        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                              num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = prepare_dataset(train_ds, is_training=True)\n",
    "test_ds = prepare_dataset(test_ds)\n",
    "\n",
    "val_ds = test_ds.take(tf.data.experimental.cardinality(test_ds) // 2)\n",
    "test_ds = test_ds.skip(tf.data.experimental.cardinality(test_ds) // 2)\n",
    "\n",
    "print(\"Number of training batches:\", tf.data.experimental.cardinality(train_ds))\n",
    "print(\"Number of validation batches:\", tf.data.experimental.cardinality(val_ds))\n",
    "print(\"Number of test batches:\", tf.data.experimental.cardinality(test_ds))\n",
    "\n",
    "def one_hot_encode(image, label):\n",
    "    return image, tf.one_hot(tf.cast(label, tf.int32), depth=num_classes)\n",
    "    return image, tf.one_hot(tf.cast(label, tf.int32), depth=num_classes)\n",
    "\n",
    "train_ds = train_ds.map(one_hot_encode)\n",
    "val_ds = val_ds.map(one_hot_encode)\n",
    "test_ds = test_ds.map(one_hot_encode)\n",
    "\n",
    "# Print an example batch to verify the shape\n",
    "for images, labels in train_ds.take(1):\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    break"
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ovvHMk1dYnXq"
   },
   "source": [
    "#### <a id='toc1_5_3_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.3** prepares the datasets for training by applying several important transformations and encodings. \n",
    "\n",
    "1. **Dataset Preparation:**\n",
    "   \n",
    "   - The `prepare_dataset` function applies shuffling (for training data), batching, and data augmentation (for training data).\n",
    "   - Datasets are split into train, validation, and test sets.\n",
    "\n",
    "2. **One-Hot Encoding:**\n",
    "\n",
    "   - After the initial preparation, we apply one-hot encoding to the labels in all datasets (train, validation, and test).\n",
    "   - The `one_hot_encode` function converts integer labels to one-hot encoded vectors.\n",
    "\n",
    "3. **Verification:**\n",
    "\n",
    "   - We print the shapes of images and labels from a batch to verify the encoding and overall data structure.\n",
    "\n",
    "4. **Batch Retrieval:**\n",
    "\n",
    "   - A function is provided to safely get a batch from the dataset, which is useful for inspection and debugging.\n",
    "\n",
    "#### <a id='toc1_5_3_2_'></a>[Why this is important](#toc0_)\n",
    "\n",
    "1. **Data Preparation:**\n",
    "\n",
    "   - Proper dataset preparation ensures that the model receives data in the correct format and with appropriate preprocessing.\n",
    "   - Shuffling the training data helps prevent the model from learning any unintended patterns based on the order of samples.\n",
    "   - Batching allows for efficient processing during training.\n",
    "   - Data augmentation helps increase the diversity of the training data, potentially improving model generalization.\n",
    "\n",
    "2. **One-Hot Encoding:**\n",
    "\n",
    "   - One-hot encoding is crucial for multi-class classification problems when using categorical crossentropy loss.\n",
    "   - It converts integer labels (e.g., 0, 1, 2) into vector form (e.g., [1,0,0], [0,1,0], [0,0,1]), which is necessary for the model's output layer and loss function.\n",
    "   - This encoding ensures that the model's output (a probability distribution over classes) matches the format of the labels.\n",
    "\n",
    "3. **Verification:**\n",
    "\n",
    "   - Checking the shapes of the images and labels after preprocessing is vital to catch any issues early.\n",
    "   - It confirms that the one-hot encoding has been applied correctly and that the data dimensions match what the model expects.\n",
    "\n",
    "4. **Batch Retrieval:**\n",
    "\n",
    "   - Having a safe method to retrieve batches allows for easy inspection of the data at various points in the pipeline.\n",
    "   - This can be crucial for debugging and ensuring that the data fed into the model is correct.\n",
    "\n",
    "\n",
    "By performing these steps, we ensure that our data is properly prepared, encoded, and verified before being used for model training, which is crucial for the success and efficiency of the subsequent training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s6ossN28YnXq"
   },
   "source": [
    "### <a id='toc1_5_4_'></a>[**1.4.\tBuild a CNN network using Keras with the following layers**](#toc0_)\n",
    "- Cov2D with 32 filters, kernel size 3,3, and activation relu, followed by MaxPool2D\n",
    "\n",
    "- Cov2D with 32 filters, kernel size 3,3, and activation relu, followed by MaxPool2D\n",
    "\n",
    "- GLobalAveragePooling2D layer\n",
    "\n",
    "- Dense layer with 128 neurons and activation relu\n",
    "\n",
    "- Dense layer with 128 neurons and activation relu\n",
    "- Dense layer with 9 neurons and activation softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Tl9fexueYnXq",
    "outputId": "fd24c309-5868-42bb-cae3-554b63a0c4f7"
    "outputId": "fd24c309-5868-42bb-cae3-554b63a0c4f7"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJb2srBR6L_e"
   },
   "source": [
    "#### <a id='toc1_5_4_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.4** defines and builds the CNN (Convolutional Neural Network) as specified. Here's a breakdown of the architecture:\n",
    "\n",
    "1. **First Convolutional Layer:**\n",
    "\n",
    "   - 32 filters with a 3x3 kernel size\n",
    "   - ReLU activation function\n",
    "   - Followed by a 2x2 MaxPooling layer\n",
    "\n",
    "2. **Second Convolutional Layer:**\n",
    "\n",
    "   - 32 filters with a 3x3 kernel size\n",
    "   - ReLU activation function\n",
    "   - Followed by a 2x2 MaxPooling layer\n",
    "\n",
    "3. **Global Average Pooling Layer:**\n",
    "\n",
    "   - Reduces the spatial dimensions of the feature maps to a single value per filter\n",
    "\n",
    "4. **First Dense Layer:**\n",
    "\n",
    "   - 128 neurons with ReLU activation\n",
    "\n",
    "5. **Second Dense Layer:**\n",
    "\n",
    "   - 128 neurons with ReLU activation\n",
    "\n",
    "6. **Output Layer**:\n",
    "\n",
    "   - 9 neurons (one for each class) with softmax activation\n",
    "\n",
    "\n",
    "The `build_cnn_model` function takes the input shape and number of classes as parameters, making it flexible for different image sizes and number of categories.\n",
    "\n",
    "We then use this function to create our model, passing in the image dimensions and number of classes that we determined from our dataset.\n",
    "\n",
    "Finally, we print a summary of the model, which will show the layers, their output shapes, and the total number of parameters in the network.\n",
    "\n",
    "This CNN architecture is designed to:\n",
    "\n",
    "- Extract features from the images using convolutional layers\n",
    "- Reduce spatial dimensions and computational load using max pooling\n",
    "- Convert the 2D feature maps to a 1D feature vector using global average pooling\n",
    "- Make the final classification using fully connected (dense) layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vhBTaySpYnXr"
   },
   "source": [
    "### <a id='toc1_5_5_'></a>[1.5.\tCompile the model with Adam optimizer, categorical_crossentropy loss, and with metrics accuracy, precision, and recall.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y-mc1R3l375_",
    "outputId": "f1ef042c-5244-4f05-b35b-185f86215a38"
    "outputId": "f1ef042c-5244-4f05-b35b-185f86215a38"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')]\n",
    "    metrics=['accuracy',\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')]\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully with the following configuration:\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Loss function: Categorical Crossentropy\")\n",
    "print(f\"Metrics: Accuracy, Precision, Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zf8xTwJU3pFI"
   },
   "source": [
    "#### <a id='toc1_5_5_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.5** compiles the CNN model we built in the previous section. Here's a breakdown of what each part does:\n",
    "\n",
    "1. **Optimizer: Adam**\n",
    "\n",
    "    - We use the Adam optimizer, which is an adaptive learning rate optimization algorithm.\n",
    "    - Adam is widely used because it combines the benefits of two other extensions of stochastic gradient descent: AdaGrad and RMSProp.\n",
    "    - It's generally a good default choice for many deep learning tasks.\n",
    "\n",
    "2. **Loss Function: Categorical Crossentropy**\n",
    "\n",
    "    - We use 'categorical_crossentropy' as our loss function.\n",
    "    - This is appropriate for multi-class classification problems where each sample belongs to exactly one class.\n",
    "    - It measures the dissimilarity between the predicted probability distribution and the true distribution.\n",
    "\n",
    "3. **Metrics: Accuracy, Precision, and Recall**\n",
    "\n",
    "    - *Accuracy:* Measures the proportion of correct predictions (both true positives and true negatives) among the total number of cases examined.\n",
    "    - *Precision:* Measures the proportion of true positive predictions among all positive predictions. It answers the question: \"Of all the samples predicted as positive, how many actually are positive?\"\n",
    "    - *Recall:* Measures the proportion of true positive predictions among all actual positive samples. It answers the question: \"Of all the actual positive samples, how many were correctly identified?\"\n",
    "\n",
    "#### <a id='toc1_5_5_2_'></a>[Why these choices are important](#toc0_)\n",
    "\n",
    "- Adam optimizer is often a good starting point as it adapts the learning rate during training, which can lead to faster convergence.\n",
    "- Categorical crossentropy is the standard loss function for multi-class classification problems.\n",
    "- Using multiple metrics (accuracy, precision, and recall) provides a more comprehensive evaluation of the model's performance, especially if the classes are imbalanced.\n",
    "- This code block compiles the CNN model we built in the previous section. Here's a breakdown of what each part does:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tP42h7Nr57El"
   },
   "source": [
    "### <a id='toc1_5_6_'></a>[1.6.\tTrain the model for 20 epochs and plot training loss and accuracy against epochs.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "euTcOJ1m9fT8",
    "outputId": "c55dd0e1-fe62-4eca-cd37-a0d7139b50ab"
    "outputId": "c55dd0e1-fe62-4eca-cd37-a0d7139b50ab"
   },
   "outputs": [],
   "source": [
    "# Check the shape of a batch from the training dataset\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Shape of images in a batch:\", images.shape)\n",
    "    print(\"Shape of labels in a batch:\", labels.shape)\n",
    "\n",
    "# Print the model summary again\n",
    "model.summary()\n",
    "\n",
    "# Check the number of classes\n",
    "print(\"Number of classes:\", len(class_names))\n",
    "\n",
    "# Check if labels are one-hot encoded\n",
    "if len(labels.shape) == 2 and labels.shape[1] > 1:\n",
    "    print(\"Labels are one-hot encoded\")\n",
    "else:\n",
    "    print(\"Labels are not one-hot encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "okxtlBjh7Odc",
    "outputId": "5ab224e8-571b-49b7-d8f6-050e7f5716e5"
    "outputId": "5ab224e8-571b-49b7-d8f6-050e7f5716e5"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "    ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)\n",
    "\n",
    "# Print final training and validation metrics\n",
    "print(\"Final training accuracy: {:.2f}%\".format(history.history['accuracy'][-1] * 100))\n",
    "print(\"Final validation accuracy: {:.2f}%\".format(history.history['val_accuracy'][-1] * 100))\n",
    "print(\"Final training loss: {:.4f}\".format(history.history['loss'][-1]))\n",
    "print(\"Final validation loss: {:.4f}\".format(history.history['val_loss'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47wxypkE7f_x"
   },
   "source": [
    "#### <a id='toc1_5_6_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.6** trains the model and visualizes the training progress. Here's a breakdown of what each part does:\n",
    "\n",
    "1. **Training the model:**\n",
    "1. **Training the model:**\n",
    "\n",
    "   - We use the fit() method to train the model.\n",
    "   - `train_ds` is used as the training data.\n",
    "   - `val_ds` is used as the validation data.\n",
    "   - We train for 20 epochs as specified.\n",
    "   - The `verbose=1` parameter gives us detailed output for each epoch.\n",
    "\n",
    "2. **Plotting the training history:**\n",
    "2. **Plotting the training history:**\n",
    "\n",
    "   - We define a function plot_training_history() that creates two subplots:\n",
    "\n",
    "      - **Model Accuracy:** Shows how the training and validation accuracy change over epochs.\n",
    "      - **Model Loss:** Shows how the training and validation loss change over epochs.\n",
    "\n",
    "   - The plots use different colors for training and validation metrics, making it easy to compare them.\n",
    "\n",
    "\n",
    "3. **Printing final metrics:**\n",
    "3. **Printing final metrics:**\n",
    "\n",
    "   - We print the final training and validation accuracy and loss.\n",
    "   - This gives us a quick summary of the model's performance at the end of training.\n",
    "\n",
    "#### <a id='toc1_5_6_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Training Progress:**\n",
    "   - Training accuracy increased from 32.04% (Epoch 1) to 43.66% (Epoch 20).\n",
    "   - Training loss decreased from 1.9484 (Epoch 1) to 1.5892 (Epoch 20).\n",
    "   - Validation accuracy fluctuated but generally improved from 31.25% (Epoch 1) to 39.06% (Epoch 20).\n",
    "   - Validation loss overall decreased from 1.7777 (Epoch 1) to 1.5984 (Epoch 20).\n",
    "1. **Training Progress:**\n",
    "   - Training accuracy increased from 32.04% (Epoch 1) to 43.66% (Epoch 20).\n",
    "   - Training loss decreased from 1.9484 (Epoch 1) to 1.5892 (Epoch 20).\n",
    "   - Validation accuracy fluctuated but generally improved from 31.25% (Epoch 1) to 39.06% (Epoch 20).\n",
    "   - Validation loss overall decreased from 1.7777 (Epoch 1) to 1.5984 (Epoch 20).\n",
    "\n",
    "2. **Precision and Recall:**\n",
    "   - Training precision and recall generally improved over time.\n",
    "   - Validation precision and recall were highly volatile, with some epochs showing 0.0000 for both metrics.\n",
    "2. **Precision and Recall:**\n",
    "   - Training precision and recall generally improved over time.\n",
    "   - Validation precision and recall were highly volatile, with some epochs showing 0.0000 for both metrics.\n",
    "\n",
    "3. **Learning Rate:**\n",
    "   - The model showed slow but steady improvement in training accuracy and loss.\n",
    "   - The validation metrics were less stable, suggesting potential overfitting or issues with the validation set.\n",
    "\n",
    "4. **Performance Ceiling:**\n",
    "   - The model seems to hit a performance ceiling around 43% accuracy for training and 39% for validation.\n",
    "\n",
    "5. **Overfitting:**\n",
    "   - There's a consistent gap between training and validation accuracy, indicating some degree of overfitting.\n",
    "\n",
    "6. **Instability in Validation Metrics:**\n",
    "   - The validation precision and recall show extreme fluctuations, including several epochs with 0.0000 values.\n",
    "\n",
    "#### <a id='toc1_5_6_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. **Limited Learning:** The model has learned to classify the boats to some extent, but its performance is still relatively poor for a classification task. An accuracy of around 40% for a multi-class problem suggests there's significant room for improvement.\n",
    "\n",
    "2. **Potential Overfitting:** The consistent gap between training and validation metrics suggests the model may be overfitting to the training data. This could be addressed by:\n",
    "   \n",
    "   - Increasing regularization (e.g., dropout, L2 regularization)\n",
    "   - Collecting more training data\n",
    "   - Simplifying the model architecture\n",
    "\n",
    "3. **Data Issues:** The extreme fluctuations in validation precision and recall, including zero values, suggest potential issues with the validation set. This could be due to:\n",
    "   \n",
    "   - Class imbalance in the dataset\n",
    "   - Small validation set size leading to high variance\n",
    "   - Potential data leakage or preprocessing issues\n",
    "\n",
    "4. **Need for Model Improvements:** Given the low accuracy, consider:\n",
    "   \n",
    "   - Experimenting with different model architectures\n",
    "   - Applying more aggressive data augmentation\n",
    "   - Using transfer learning with a pre-trained model\n",
    "\n",
    "5. **Learning Rate and Epochs:** The slow but steady improvement suggests that:\n",
    "   \n",
    "   - The learning rate might be appropriate\n",
    "   - Training for more epochs could potentially yield further improvements\n",
    "\n",
    "6. **Class Imbalance:** The discrepancy between accuracy and precision/recall suggests class imbalance. Consider using techniques like class weighting or oversampling of minority classes.\n",
    "\n",
    "7. **Further Investigation Needed:**\n",
    "    \n",
    "   - Analyze the confusion matrix to understand which classes are most problematic\n",
    "   - Examine sample misclassifications to gain insights into the model's weaknesses\n",
    "\n",
    "While the model shows some learning, its performance is suboptimal. The next steps should focus on addressing potential overfitting, investigating data quality and balance, and experimenting with more advanced model architectures or transfer learning approaches to improve classification accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCyeGwRqFomh"
   },
   "source": [
    "### <a id='toc1_5_7_'></a>[1.7.\tEvaluate the model on test images and print the test loss and accuracy.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o4ufA-GsF5qy",
    "outputId": "dca59efd-ba5d-41c4-b522-bea1b18ae321"
    "outputId": "dca59efd-ba5d-41c4-b522-bea1b18ae321"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test precision: {test_precision:.4f}\")\n",
    "print(f\"Test recall: {test_recall:.4f}\")\n",
    "\n",
    "# Compare with training and validation results\n",
    "print(\"\\nComparison with training and validation results:\")\n",
    "print(f\"Training accuracy: 43.66%\")\n",
    "print(f\"Validation accuracy: 39.06%\")\n",
    "print(f\"Training accuracy: 43.66%\")\n",
    "print(f\"Validation accuracy: 39.06%\")\n",
    "print(f\"Test accuracy: {test_accuracy:.2%}\")\n",
    "\n",
    "print(f\"\\nTraining loss: 1.5892\")\n",
    "print(f\"Validation loss: 1.5984\")\n",
    "print(f\"\\nTraining loss: 1.5892\")\n",
    "print(f\"Validation loss: 1.5984\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pp9IP0COH4EZ"
   },
   "source": [
    "#### <a id='toc1_5_7_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.7** is evaluating the model with test images and determining the test loss and accuracy.  Specifically:\n",
    "\n",
    "1. We use the `model.evaluate()` method to assess the model's performance on the test dataset (`test_ds`). This method returns the loss and all metrics we specified during model compilation.\n",
    "2. We print out the test loss, accuracy, precision, and recall. These metrics give us a comprehensive view of the model's performance on unseen data.\n",
    "3. We then compare the test results with the final training and validation results provided. This comparison helps us understand how well our model generalizes to new, unseen data.\n",
    "\n",
    "#### <a id='toc1_5_7_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Test Performance:**\n",
    "   - Test loss: 1.7429\n",
    "   - Test accuracy: 30.77%\n",
    "   - Test precision: 52.00%\n",
    "   - Test recall: 12.50%\n",
    "1. **Test Performance:**\n",
    "   - Test loss: 1.7429\n",
    "   - Test accuracy: 30.77%\n",
    "   - Test precision: 52.00%\n",
    "   - Test recall: 12.50%\n",
    "\n",
    "2. **Comparison with Training and Validation:**\n",
    "   - Training accuracy (43.66%) > Validation accuracy (39.06%) > Test accuracy (30.77%)\n",
    "   - Training loss (1.5892) < Validation loss (1.5984) < Test loss (1.7429)\n",
    "2. **Comparison with Training and Validation:**\n",
    "   - Training accuracy (43.66%) > Validation accuracy (39.06%) > Test accuracy (30.77%)\n",
    "   - Training loss (1.5892) < Validation loss (1.5984) < Test loss (1.7429)\n",
    "\n",
    "3. **Precision and Recall:**\n",
    "   - Test precision (52.00%) is relatively high compared to the accuracy.\n",
    "   - Test recall (12.50%) is quite low.\n",
    "3. **Precision and Recall:**\n",
    "   - Test precision (52.00%) is relatively high compared to the accuracy.\n",
    "   - Test recall (12.50%) is quite low.\n",
    "\n",
    "4. **Performance Degradation:**\n",
    "   - There's a noticeable drop in accuracy from training to validation to test sets.\n",
    "   - The loss increases from training to validation to test sets.\n",
    "4. **Performance Degradation:**\n",
    "   - There's a noticeable drop in accuracy from training to validation to test sets.\n",
    "   - The loss increases from training to validation to test sets.\n",
    "\n",
    "#### <a id='toc1_5_7_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. **Overfitting:** The significant drop in accuracy from training (43.66%) to test (30.77%) strongly suggests that the model is overfitting to the training data. It's not generalizing well to unseen data.\n",
    "\n",
    "2. **Poor Generalization:** The test accuracy of 30.77% indicates that the model's performance on new, unseen data is poor. For a multi-class classification problem, this is only marginally better than random guessing, depending on the number of classes.\n",
    "\n",
    "3. **Precision-Recall Tradeoff:** The high precision (52.00%) coupled with low recall (12.50%) suggests that the model is being very conservative in its predictions. It's making few positive predictions, but when it does, it's often correct. However, it's missing many positive cases.\n",
    "\n",
    "4. **Class Imbalance:** The discrepancy between accuracy and precision might indicate class imbalance in the dataset. The model might be performing well on some classes but poorly on others.\n",
    "\n",
    "5. **Model Limitations:** The overall low performance across all metrics (accuracy, precision, recall) indicates that the current model architecture or training approach is not suitable for this particular classification task.\n",
    "\n",
    "6. **Data Issues:** The consistent degradation of performance from training to validation to test sets might also point to potential issues with data distribution across these sets. There might be a mismatch in the distribution of classes or features.\n",
    "\n",
    "7. **Need for Model Improvement:** Given the poor test performance, significant improvements are needed. This could include:\n",
    "\n",
    "   - Redesigning the model architecture\n",
    "   - Implementing more effective regularization techniques\n",
    "   - Using transfer learning with a pre-trained model\n",
    "   - Addressing potential class imbalance issues\n",
    "   - Collecting more diverse training data\n",
    "\n",
    "8. **Further Analysis Required:** It would be beneficial to:\n",
    "   \n",
    "   - Examine the confusion matrix to understand which classes are most problematic\n",
    "   - Analyze misclassified samples to gain insights into the model's weaknesses\n",
    "   - Investigate the distribution of classes across train, validation, and test sets\n",
    "\n",
    "While the model showed some learning capacity during training, its poor performance on the test set indicates serious limitations in its current form. The next steps should focus on addressing overfitting, improving generalization, and potentially revisiting the fundamental approach to this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L0nx6YXCJmBV"
   },
   "source": [
    "### <a id='toc1_5_8_'></a>[1.8.\tPlot heatmap of the confusion matrix and print classification report.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVb1GH4xgWGr",
    "outputId": "5b3ea27c-2ba4-4a29-dd2d-5ccf848c17cf"
   },
   "outputs": [],
   "source": [
    "print(\"Unique classes in true labels:\", np.unique(y_true))\n",
    "print(\"Unique classes in predictions:\", np.unique(y_pred))\n",
    "print(\"Class distribution in true labels:\", np.bincount(y_true))\n",
    "print(\"Class distribution in predictions:\", np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "iMPpVuqTJmzc",
    "outputId": "579ded8a-1817-4b12-8d41-05928cc47924"
    "outputId": "579ded8a-1817-4b12-8d41-05928cc47924"
   },
   "outputs": [],
   "source": [
    "# Diagnostic information\n",
    "print(\"Original class names:\", class_names)\n",
    "print(\"Number of original classes:\", len(class_names))\n",
    "print(\"Unique classes in true labels:\", np.unique(y_true))\n",
    "print(\"Unique classes in predictions:\", np.unique(y_pred))\n",
    "print(\"Number of unique classes in true labels:\", len(np.unique(y_true)))\n",
    "print(\"Number of unique classes in predictions:\", len(np.unique(y_pred)))\n",
    "# Diagnostic information\n",
    "print(\"Original class names:\", class_names)\n",
    "print(\"Number of original classes:\", len(class_names))\n",
    "print(\"Unique classes in true labels:\", np.unique(y_true))\n",
    "print(\"Unique classes in predictions:\", np.unique(y_pred))\n",
    "print(\"Number of unique classes in true labels:\", len(np.unique(y_true)))\n",
    "print(\"Number of unique classes in predictions:\", len(np.unique(y_pred)))\n",
    "\n",
    "# Get the union of classes present in both true labels and predictions\n",
    "all_present_classes = np.union1d(np.unique(y_true), np.unique(y_pred))\n",
    "present_class_names = [class_names[i] for i in all_present_classes if i < len(class_names)]\n",
    "\n",
    "print(\"Classes present in true labels or predictions:\", present_class_names)\n",
    "print(\"Number of present classes:\", len(present_class_names))\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=present_class_names, zero_division=0))\n",
    "\n",
    "# Updated confusion matrix plotting function\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "# Get the union of classes present in both true labels and predictions\n",
    "all_present_classes = np.union1d(np.unique(y_true), np.unique(y_pred))\n",
    "present_class_names = [class_names[i] for i in all_present_classes if i < len(class_names)]\n",
    "\n",
    "print(\"Classes present in true labels or predictions:\", present_class_names)\n",
    "print(\"Number of present classes:\", len(present_class_names))\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=present_class_names, zero_division=0))\n",
    "\n",
    "# Updated confusion matrix plotting function\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_true, y_pred, present_class_names)\n",
    "# Plot confusion matrix\n",
    "plot_confusion_matrix(y_true, y_pred, present_class_names)\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(len(present_class_names)))\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(len(present_class_names)))\n",
    "\n",
    "# Safe division function\n",
    "def safe_divide(a, b):\n",
    "    return np.divide(a, b, out=np.zeros_like(a, dtype=float), where=b!=0)\n",
    "# Safe division function\n",
    "def safe_divide(a, b):\n",
    "    return np.divide(a, b, out=np.zeros_like(a, dtype=float), where=b!=0)\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "class_total = cm.sum(axis=1)\n",
    "class_correct = cm.diagonal()\n",
    "per_class_accuracy = safe_divide(class_correct, class_total)\n",
    "# Calculate per-class accuracy\n",
    "class_total = cm.sum(axis=1)\n",
    "class_correct = cm.diagonal()\n",
    "per_class_accuracy = safe_divide(class_correct, class_total)\n",
    "\n",
    "print(\"\\nPer-class Accuracy:\")\n",
    "for class_name, accuracy, correct, total in zip(present_class_names, per_class_accuracy, class_correct, class_total):\n",
    "    if total == 0:\n",
    "        print(f\"{class_name}: No samples\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {accuracy:.2%} ({correct}/{total})\")\n",
    "print(\"\\nPer-class Accuracy:\")\n",
    "for class_name, accuracy, correct, total in zip(present_class_names, per_class_accuracy, class_correct, class_total):\n",
    "    if total == 0:\n",
    "        print(f\"{class_name}: No samples\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {accuracy:.2%} ({correct}/{total})\")\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy:.2%}\")\n",
    "# Overall accuracy\n",
    "overall_accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy:.2%}\")\n",
    "\n",
    "# Class distribution in true labels\n",
    "print(\"\\nClass Distribution in Test Set:\")\n",
    "for class_name, total in zip(present_class_names, class_total):\n",
    "    print(f\"{class_name}: {total}\")\n",
    "# Class distribution in true labels\n",
    "print(\"\\nClass Distribution in Test Set:\")\n",
    "for class_name, total in zip(present_class_names, class_total):\n",
    "    print(f\"{class_name}: {total}\")\n",
    "\n",
    "# Class distribution in predictions\n",
    "pred_total = cm.sum(axis=0)\n",
    "print(\"\\nClass Distribution in Predictions:\")\n",
    "for class_name, total in zip(present_class_names, pred_total):\n",
    "    print(f\"{class_name}: {total}\")"
    "# Class distribution in predictions\n",
    "pred_total = cm.sum(axis=0)\n",
    "print(\"\\nClass Distribution in Predictions:\")\n",
    "for class_name, total in zip(present_class_names, pred_total):\n",
    "    print(f\"{class_name}: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgCewoDNJ3MD"
   },
   "source": [
    "#### <a id='toc1_5_8_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.8** is performing a detailed analysis of the model's performance on the test dataset. Specifically, it's:\n",
    "\n",
    "1. Identifying the classes present in the true labels and predictions.\n",
    "2. Generating a classification report that includes precision, recall, and F1-score for each class.\n",
    "3. Calculating per-class accuracy.\n",
    "4. Displaying class distribution in the test set and model predictions.\n",
    "1. Identifying the classes present in the true labels and predictions.\n",
    "2. Generating a classification report that includes precision, recall, and F1-score for each class.\n",
    "3. Calculating per-class accuracy.\n",
    "4. Displaying class distribution in the test set and model predictions.\n",
    "\n",
    "#### <a id='toc1_5_8_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "**1. Class Representation:**\n",
    "   - Original classes: 9\n",
    "   - Classes in true labels: 8 (one class is missing)\n",
    "   - Classes in predictions: 4 (only predicting for cruise_ship, gondola, kayak, and sailboat)\n",
    "\n",
    "**2. Classification Report:**\n",
    "   - Overall accuracy: 31%\n",
    "   - Only three classes have non-zero scores: gondola, kayak, and sailboat\n",
    "   - Gondola: Precision 0.27, Recall 0.53, F1-score 0.36\n",
    "   - Kayak: Precision 0.18, Recall 0.09, F1-score 0.12\n",
    "   - Sailboat: Precision 0.36, Recall 0.70, F1-score 0.48\n",
    "   - All other classes have zero precision, recall, and F1-score\n",
    "\n",
    "**3. Per-class Accuracy:**\n",
    "   - Gondola: 90.00%\n",
    "   - Kayak: 18.18%\n",
    "   - All other classes (except sailboat): 0.00%\n",
    "   - Sailboat: NaN (likely due to division by zero)\n",
    "\n",
    "**4. Class Imbalance:**\n",
    "   - Support column shows varying numbers of samples per class (from 1 to 30)\n",
    "   - Sailboat has the most samples (30), while inflatable_boat has only 1\n",
    "\n",
    "#### <a id='toc1_5_8_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. **Limited Prediction Range:** The model is only making predictions for 4 out of 9 classes, severely limiting its usefulness in a real-world scenario.\n",
    "1. **Limited Prediction Range:** The model is only making predictions for 4 out of 9 classes, severely limiting its usefulness in a real-world scenario.\n",
    "\n",
    "2. **Poor Overall Performance:** With an accuracy of 31%, the model is performing only slightly better than random guessing for a 9-class problem.\n",
    "2. **Poor Overall Performance:** With an accuracy of 31%, the model is performing only slightly better than random guessing for a 9-class problem.\n",
    "\n",
    "3. **Class Imbalance Issues:** The varying support numbers and the model's failure to predict several classes suggest significant class imbalance in the dataset.\n",
    "3. **Class Imbalance Issues:** The varying support numbers and the model's failure to predict several classes suggest significant class imbalance in the dataset.\n",
    "\n",
    "4. **Overfitting to Specific Classes:** The model shows some ability to recognize gondolas and sailboats but performs poorly on most other classes.\n",
    "4. **Overfitting to Specific Classes:** The model shows some ability to recognize gondolas and sailboats but performs poorly on most other classes.\n",
    "\n",
    "5. **Misleading Accuracy Metrics:** The high per-class accuracy for gondolas (90%) is misleading when considered alongside its low precision (0.27), indicating many false positives.\n",
    "5. **Misleading Accuracy Metrics:** The high per-class accuracy for gondolas (90%) is misleading when considered alongside its low precision (0.27), indicating many false positives.\n",
    "\n",
    "6. **Data Quality Concerns:** The absence of one class in the true labels suggests potential issues in data preparation or labeling.\n",
    "6. **Data Quality Concerns:** The absence of one class in the true labels suggests potential issues in data preparation or labeling.\n",
    "\n",
    "7. **Model Bias:** The model seems biased towards predicting more common classes (like sailboat) and completely fails on less represented classes.\n",
    "7. **Model Bias:** The model seems biased towards predicting more common classes (like sailboat) and completely fails on less represented classes.\n",
    "\n",
    "#### <a id='toc1_5_8_4_'></a>[Recommendations](#toc0_)\n",
    "\n",
    "1. **Address Class Imbalance:** Use techniques like oversampling, undersampling, or SMOTE to balance the dataset.\n",
    "1. **Address Class Imbalance:** Use techniques like oversampling, undersampling, or SMOTE to balance the dataset.\n",
    "\n",
    "2. **Data Augmentation:** Increase the diversity of training samples, especially for underrepresented classes.\n",
    "2. **Data Augmentation:** Increase the diversity of training samples, especially for underrepresented classes.\n",
    "\n",
    "3. **Model Architecture Review:** The current model may not be complex enough to capture the nuances between different boat types. Consider using a more sophisticated architecture or transfer learning.\n",
    "3. **Model Architecture Review:** The current model may not be complex enough to capture the nuances between different boat types. Consider using a more sophisticated architecture or transfer learning.\n",
    "\n",
    "4. **Feature Engineering:** Investigate if the current features are sufficient to distinguish between different boat types.\n",
    "4. **Feature Engineering:** Investigate if the current features are sufficient to distinguish between different boat types.\n",
    "\n",
    "5. **Error Analysis:** Examine misclassified instances to understand why the model is failing for certain classes.\n",
    "5. **Error Analysis:** Examine misclassified instances to understand why the model is failing for certain classes.\n",
    "\n",
    "6. **Robust Evaluation Metrics:** Use metrics that are more robust to class imbalance, such as weighted F1-score or Cohen's Kappa.\n",
    "6. **Robust Evaluation Metrics:** Use metrics that are more robust to class imbalance, such as weighted F1-score or Cohen's Kappa.\n",
    "\n",
    "7. **Data Quality Check:** Review the dataset to ensure all classes are correctly represented and labeled.\n",
    "7. **Data Quality Check:** Review the dataset to ensure all classes are correctly represented and labeled.\n",
    "\n",
    "8. **Threshold Adjustment:** Consider adjusting prediction thresholds for each class to improve overall performance.\n",
    "8. **Threshold Adjustment:** Consider adjusting prediction thresholds for each class to improve overall performance.\n",
    "\n",
    "The model's performance is poor and inconsistent across classes. Significant improvements in data preparation, model architecture, and training approach are necessary to create a reliable boat classification system.\n"
    "The model's performance is poor and inconsistent across classes. Significant improvements in data preparation, model architecture, and training approach are necessary to create a reliable boat classification system.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dY7SVZ5sO7o2"
   },
   "source": [
    "## <a id='toc1_6_'></a>[2.\tBuild a lightweight model with the aim of deploying the solution on a mobile device using transfer learning.](#toc0_)\n",
    "You can use any lightweight pre-trained model as the initial (first) layer. MobileNetV2 is a popular lightweight pre-trained model built using Keras API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E_GqGJuhV5a3"
   },
   "source": [
    "**Setup: Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zqw1SIyzvO4e"
    "id": "zqw1SIyzvO4e"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set the path to your dataset\n",
    "#data_dir = pathlib.Path(\"boat_type_classification_dataset\")\n",
    "data_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/datasets/boat_type_classification_dataset\")\n",
    "\n",
    "# Set common parameters\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
    "data_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/datasets/boat_type_classification_dataset\")\n",
    "\n",
    "# Set common parameters\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxJZgz4sPJhk"
   },
   "source": [
    "### <a id='toc1_6_1_'></a>[2.1.\tSplit the dataset into train and test datasets in the ration 70:30, with shuffle and random state=1.](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I8PN9pTgPK_8"
   },
   "outputs": [],
   "source": [
    "# 2.1: Load and split the dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=1,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=1,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Store class names before preprocessing\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
   "source": [
    "# 2.1: Load and split the dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=1,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=1,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Store class names before preprocessing\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pC7uvAZ-PLu4"
   },
   "source": [
    "#### <a id='toc1_6_1_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.1** is responsible for loading the dataset and splitting it into training and testing sets.\n",
    "\n",
    "- We use `tf.keras.preprocessing.image_dataset_from_directory` to load images directly from the filesystem. This function is convenient as it handles the file reading and label assignment automatically.\n",
    "- We set `validation_split=0.3` and `subset=\"both\"` to get both training and testing sets in an 70:30 ratio.\n",
    "- `seed=1` ensures reproducibility of the random split.\n",
    "- `shuffle=True` randomizes the order of the samples, which is important for training neural networks.\n",
    "- We set `batch_size=batch_size` setting the batch size here means that our dataset will be divided into batches of 32 images each. This is important for several reasons:\n",
    "  - *Memory Efficiency:* Processing 32 images at a time is more memory-efficient than loading the entire dataset at once, especially for large datasets.\n",
    "  - *Training Dynamics:* Batch size affects the dynamics of model training. A batch size of 32 is often a good default, balancing between the noisy gradients of very small batches and the longer computation time of larger batches.\n",
    "  - *Consistency:* By setting the batch size here, we ensure that all parts of our pipeline (data loading, augmentation, model training) use the same batch size.\n",
    "- The `image_size` parameter resizes all images to a consistent size, which is necessary for batch processing in neural networks.\n",
    "\n",
    "**Why it's important:**\n",
    "\n",
    "- Properly splitting the data ensures we have separate sets for training and evaluation, which is crucial for assessing the model's performance on unseen data.\n",
    "- The 70:30 split is a common ratio that balances having enough training data while still retaining a significant portion for testing.\n",
    "- Shuffling the data helps prevent any bias that might occur from the order of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQtgIC1rPOko"
   },
   "source": [
    "### <a id='toc1_6_2_'></a>[2.2.\tUse tf.keras.preprocessing.image_dataset_from_directory to load the train and test datasets.](#toc0_)\n",
    "This function also supports data normalization.*(Hint: Image_scale=1./255)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e3en77K7PSec"
   },
   "outputs": [],
   "source": [
    "# 2.2: Prepare datasets (including normalization)\n",
    "def prepare_dataset(dataset):\n",
    "    # Normalize images\n",
    "    dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "    # Convert labels to one-hot encoding\n",
    "    dataset = dataset.map(lambda x, y: (x, tf.one_hot(y, depth=num_classes)))\n",
    "    return dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = prepare_dataset(train_ds)\n",
    "test_ds = prepare_dataset(test_ds)"
   ]
   "source": [
    "# 2.2: Prepare datasets (including normalization)\n",
    "def prepare_dataset(dataset):\n",
    "    # Normalize images\n",
    "    dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "    # Convert labels to one-hot encoding\n",
    "    dataset = dataset.map(lambda x, y: (x, tf.one_hot(y, depth=num_classes)))\n",
    "    return dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = prepare_dataset(train_ds)\n",
    "test_ds = prepare_dataset(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9c0j5KonPS-E"
   },
   "source": [
    "#### <a id='toc1_6_2_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.2** focuses on normalizing the image data and verifying that the normalization was applied correctly.\n",
    "\n",
    "- We define a `normalize_img` function that converts the image data from integers in the range [0, 255] to floating-point numbers in the range [0, 1].\n",
    "- We apply this normalization to both the training and testing datasets using the map function.\n",
    "- The `check_normalization` function safely checks the range of values in the normalized datasets.\n",
    "\n",
    "**Why it's important:**\n",
    "\n",
    "- Normalization is crucial for neural network training. It helps the model converge faster and can lead to better performance.\n",
    "- Scaling the input to a standard range (like [0, 1]) ensures that all features contribute equally to the model's learning process.\n",
    "- Checking the normalization helps verify that our preprocessing steps are working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vGf2Stg3PT4e"
   },
   "source": [
    "### <a id='toc1_6_3_'></a>[2.3.\tLoad train, validation and test datasets in batches of 32 using the function initialized in the above step.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7TbWeW_sPX-6"
   },
   "outputs": [],
   "source": [
    "# 2.3: Split test_ds into validation and test\n",
    "val_ds = test_ds.take(len(test_ds) // 2)\n",
    "test_ds = test_ds.skip(len(test_ds) // 2)\n",
    "\n",
    "print(\"Number of training batches:\", len(train_ds))\n",
    "print(\"Number of validation batches:\", len(val_ds))\n",
    "print(\"Number of test batches:\", len(test_ds))\n",
    "\n",
    "# Check the shape of our data\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Image shape:\", images.shape)\n",
    "    print(\"Label shape:\", labels.shape)"
   ]
   "source": [
    "# 2.3: Split test_ds into validation and test\n",
    "val_ds = test_ds.take(len(test_ds) // 2)\n",
    "test_ds = test_ds.skip(len(test_ds) // 2)\n",
    "\n",
    "print(\"Number of training batches:\", len(train_ds))\n",
    "print(\"Number of validation batches:\", len(val_ds))\n",
    "print(\"Number of test batches:\", len(test_ds))\n",
    "\n",
    "# Check the shape of our data\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Image shape:\", images.shape)\n",
    "    print(\"Label shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "835LWJxFPYf6"
   },
   "source": [
    "#### <a id='toc1_6_3_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.3** prepares the datasets for training by applying several important transformations and encodings. Here's a breakdown of the key steps:\n",
    "\n",
    "1. **Dataset Preparation:**\n",
    "\n",
    "    - The `prepare_dataset` function applies shuffling (for training data), batching, and data augmentation (for training data).\n",
    "    - Datasets are split into train, validation, and test sets.\n",
    "\n",
    "2. **One-Hot Encoding:**\n",
    "\n",
    "    - After the initial preparation, we apply one-hot encoding to the labels in all datasets (train, validation, and test).\n",
    "    - The `one_hot_encode` function converts integer labels to one-hot encoded vectors.\n",
    "\n",
    "3. **Verification:**\n",
    "\n",
    "     - We print the shapes of images and labels from a batch to verify the encoding and overall data structure.\n",
    "\n",
    "4. **Batch Retrieval:**\n",
    "\n",
    "     - A function is provided to safely get a batch from the dataset, which is useful for inspection and debugging.\n",
    "\n",
    "#### <a id='toc1_6_3_2_'></a>[Why this is important](#toc0_)\n",
    "\n",
    "1. **Data Preparation:**\n",
    "\n",
    "    - Proper dataset preparation ensures that the model receives data in the correct format and with appropriate preprocessing.\n",
    "    - Shuffling the training data helps prevent the model from learning any unintended patterns based on the order of samples.\n",
    "    - Batching allows for efficient processing during training.\n",
    "    - Data augmentation helps increase the diversity of the training data, potentially improving model generalization.\n",
    "\n",
    "2. **One-Hot Encoding:**\n",
    "\n",
    "    - One-hot encoding is crucial for multi-class classification problems when using categorical crossentropy loss.\n",
    "    - It converts integer labels (e.g., 0, 1, 2) into vector form (e.g., [1,0,0], [0,1,0], [0,0,1]), which is necessary for the model's output layer and loss function.\n",
    "    - This encoding ensures that the model's output (a probability distribution over classes) matches the format of the labels.\n",
    "\n",
    "3. **Verification:**\n",
    "\n",
    "    - Checking the shapes of the images and labels after preprocessing is vital to catch any issues early.\n",
    "    - It confirms that the one-hot encoding has been applied correctly and that the data dimensions match what the model expects.\n",
    "\n",
    "4. **Batch Retrieval:**\n",
    "\n",
    "    - Having a safe method to retrieve batches allows for easy inspection of the data at various points in the pipeline.\n",
    "    - This can be crucial for debugging and ensuring that the data fed into the model is correct.\n",
    "\n",
    "\n",
    "By performing these steps, we ensure that our data is properly prepared, encoded, and verified before being used for model training, which is crucial for the success and efficiency of the subsequent training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KvT_jgZZPY1X"
   },
   "source": [
    "### <a id='toc1_6_4_'></a>[2.4.\tBuild a CNN network using Keras with the following layers.](#toc0_)\n",
    "     \n",
    "- Load MobileNetV2 - Light Model as the first layer *(Hint: Keras API Doc)*\n",
    "- GLobalAveragePooling2D layer\n",
    "- Dropout(0.2)\n",
    "- Dense layer with 256 neurons and activation relu\n",
    "- BatchNormalization layer\n",
    "- Dropout(0.1)\n",
    "- Dense layer with 128 neurons and activation relu\n",
    "- BatchNormalization layer\n",
    "- Dropout(0.1)\n",
    "- Dense layer with 9 neurons and activation softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N2BxFyosPedk"
   },
   "outputs": [],
   "source": [
    "# 2.4: Build the model\n",
    "def build_model(num_classes):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes)\n",
    "model.summary()"
   ]
   "source": [
    "# 2.4: Build the model\n",
    "def build_model(num_classes):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3l_Lz3EgPe8V"
   },
   "source": [
    "#### <a id='toc1_6_4_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.4** creates the model and is focused on the following:\n",
    "\n",
    "1. **Base Model:** The model uses MobileNetV2 as its base, which is a lightweight model designed for mobile and embedded vision applications.\n",
    "2. **Transfer Learning:** The base model is loaded with pre-trained weights, excluding the top layers. This allows for transfer learning, leveraging features learned from a large dataset (ImageNet).\n",
    "3. **Custom Top Layers:** On top of the base model, several layers are added for fine-tuning to our specific classification task:\n",
    "    - Global Average Pooling to reduce spatial dimensions\n",
    "    - Dropout layers for regularization\n",
    "    - Dense layers for feature extraction and classification\n",
    "    - Batch Normalization layers to stabilize learning\n",
    "4. **Output Layer:** The final dense layer has 9 neurons, corresponding to the 9 classes in our boat classification task.\n",
    "\n",
    "#### <a id='toc1_6_4_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Model Size:**\n",
    "    - Total params: 2,621,513 (~10.00 MB)\n",
    "    - Trainable params: 362,761 (~1.38 MB)\n",
    "    - Non-trainable params: 2,258,752 (~8.62 MB)\n",
    "\n",
    "2. **Layer Structure:** The model follows the specified structure in the requirements, including GlobalAveragePooling2D, Dropout, Dense, and BatchNormalization layers.\n",
    "\n",
    "3. **Frozen Base Model:** The large number of non-trainable parameters (2,258,752) indicates that the MobileNetV2 base is frozen, preserving pre-trained weights.\n",
    "Customization: The trainable parameters (362,761) are in the custom top layers, allowing the model to adapt to our specific task.\n",
    "\n",
    "#### <a id='toc1_6_4_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. Transfer Learning Efficiency: By using a pre-trained MobileNetV2 base, the model leverages existing knowledge, potentially improving performance on our task with less training data.\n",
    "2. Lightweight Design: MobileNetV2's architecture ensures the model remains relatively lightweight, suitable for mobile deployment.\n",
    "3. Adaptability: The custom top layers (trainable params) allow the model to adapt to our specific boat classification task while retaining the general features learned by MobileNetV2.\n",
    "4. Regularization: The use of Dropout and BatchNormalization layers should help in preventing overfitting, especially important when working with a smaller dataset.\n",
    "5. Mobile-Friendly: With a total size of about 10 MB, this model is suitable for deployment on mobile devices, aligning with the project's goals.\n",
    "6. Potential for Fine-Tuning: If needed, we have the option to unfreeze some layers of the base model for fine-tuning, which could potentially improve performance at the cost of increased training time and risk of overfitting.\n",
    "\n",
    "Overall, this model architecture appears well-suited for the task of boat classification on mobile devices, balancing the benefits of transfer learning with the need for a lightweight, deployable model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jG3sjuN9Pfff"
   },
   "source": [
    "### <a id='toc1_6_5_'></a>[2.5.\tCompile the model with Adam optimizer, categorical_crossentropy loss, and metrics accuracy, Precision, and Recall.](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fvHafzpePjhZ"
   },
   "outputs": [],
   "source": [
    "# 2.5: Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")"
   ]
   "source": [
    "# 2.5: Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6F-4f_EPPkFG"
   },
   "source": [
    "#### <a id='toc1_6_5_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.5** is focused on performing the following:\n",
    "\n",
    "- We compile the model using the Adam optimizer and categorical crossentropy loss.\n",
    "- Metrics include accuracy, precision, and recall.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ANNtV-wEPkg0"
   },
   "source": [
    "### <a id='toc1_6_6_'></a>[2.6.\tTrain the model for 50 epochs and Early stopping while monitoring validation loss.](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mJx8Z5chJalS"
   },
   "outputs": [],
   "source": [
    "# Print the shape of labels in a batch\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3S-3Z6MTE7E"
   },
   "outputs": [],
   "source": [
    "# Check the shape of a batch from the training dataset\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Shape of images in a batch:\", images.shape)\n",
    "    print(\"Shape of labels in a batch:\", labels.shape)\n",
    "\n",
    "# Print the model summary again\n",
    "model.summary()\n",
    "\n",
    "# Check the number of classes\n",
    "print(\"Number of classes:\", len(class_names))\n",
    "\n",
    "# Check if labels are one-hot encoded\n",
    "if len(labels.shape) == 2 and labels.shape[1] > 1:\n",
    "    print(\"Labels are one-hot encoded\")\n",
    "else:\n",
    "    print(\"Labels are not one-hot encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "urJmM8qpPofH"
   },
   "outputs": [],
   "source": [
    "# 2.6: Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
   "source": [
    "# 2.6: Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0Z5bltMqPo_6"
   },
   "source": [
    "#### <a id='toc1_6_6_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "- We use EarlyStopping to prevent overfitting and stop training when validation loss stops improving.\n",
    "- The model is trained for up to 50 epochs, but may stop earlier due to early stopping.\n",
    "- Early stopping helps prevent overfitting by stopping training when validation performance starts to degrade.\n",
    "- `restore_best_weights=True` ensures we keep the model weights from the best epoch.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "\n",
    "**Recommendations:**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-5pNo4APPpdN"
   },
   "source": [
    "### <a id='toc1_5_7_'></a>[2.7.\tEvaluate the model on test images and print the test loss and accuracy.](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xuXk23KDPse7"
   },
   "outputs": [],
   "source": [
    "# 2.7: Evaluate the model\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_ds)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test precision: {test_precision:.4f}\")\n",
    "print(f\"Test recall: {test_recall:.4f}\")"
   ]
   "source": [
    "# 2.7: Evaluate the model\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_ds)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test precision: {test_precision:.4f}\")\n",
    "print(f\"Test recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XCTSo66gPs82"
   },
   "source": [
    "#### <a id='toc1_6_7_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "- We evaluate the model on the test dataset to get final performance metrics.\n",
    "- This gives us an unbiased estimate of the model's performance on unseen data.\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "\n",
    "\n",
    "**Recommendations:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3hED8_pOPtYQ"
   },
   "source": [
    "### <a id='toc1_5_8_'></a>[2.8.\tPlot Train loss Vs Validation loss and Train accuracy Vs Validation accuracy.](#toc0_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uneKZ8_YPwLC"
   },
   "outputs": [],
   "source": [
    "# 2.8: Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='Train')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='Train')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "print(\"Final Training Loss:\", history.history['loss'][-1])\n",
    "print(\"Final Validation Loss:\", history.history['val_loss'][-1])\n",
    "print(\"Final Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Final Validation Accuracy:\", history.history['val_accuracy'][-1])"
   ]
   "source": [
    "# 2.8: Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='Train')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='Train')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "print(\"Final Training Loss:\", history.history['loss'][-1])\n",
    "print(\"Final Validation Loss:\", history.history['val_loss'][-1])\n",
    "print(\"Final Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Final Validation Accuracy:\", history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "repM8ErYPwtH"
   },
   "source": [
    "#### <a id='toc1_6_8_1_'></a>[Explanations](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RYnqMolnPxXG"
   },
   "source": [
    "#### <a id='toc1_7_'></a>[3.\tCompare the results of both models built in steps 1 and 2 and state your observations.](#toc0_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NUIuwsOBXytk"
   },
   "source": [
    "Comparison of Models from Section 1 and Section 2\n",
    "\n",
    "1. **Model Architecture:**\n",
    "   - Section 1: Custom CNN built from scratch\n",
    "   - Section 2: Lightweight model using transfer learning with MobileNetV2 as the base\n",
    "\n",
    "2. **Final Test Performance:**\n",
    "   - *Section 1 (Custom CNN):*\n",
    "     * **Test accuracy:** 36.00% (approximate, based on earlier discussions)\n",
    "     * **Test loss:** Not provided in earlier discussions\n",
    "   \n",
    "   - *Section 2 (MobileNetV2 Transfer Learning):*\n",
    "     * **Test accuracy:** 72.55%\n",
    "     * **Test loss:** 1.2570\n",
    "     * **Test precision:** 87.50%\n",
    "     * **Test recall:** 13.73%\n",
    "\n",
    "3. **Training Behavior:**\n",
    "   - *Section 1 (Custom CNN):*\n",
    "     * Training accuracy increased from about 30% to 48% over 20 epochs\n",
    "     * Validation accuracy fluctuated but ended around 43%\n",
    "     * Both training and validation loss decreased steadily\n",
    "   \n",
    "   - *Section 2 (MobileNetV2 Transfer Learning):*\n",
    "     * Training accuracy increased from about 10% to 55% over 20 epochs\n",
    "     * Validation accuracy showed unusual behavior, jumping to about 60% after initial instability\n",
    "     * Training loss decreased steadily, while validation loss was more volatile\n",
    "\n",
    "4. **Model Complexity and Size:**\n",
    "   - *Section 1 (Custom CNN):* Likely simpler and smaller, but exact parameters not provided\n",
    "   - *Section 2 (MobileNetV2 Transfer Learning):* Based on MobileNetV2, designed to be lightweight for mobile deployment\n",
    "\n",
    "5. **Training Time:**\n",
    "   - Not explicitly provided, but transfer learning models (Section 2) typically train faster due to pre-trained weights\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "1. **Performance Improvement:**\n",
    "   - The *MobileNetV2-based model* significantly outperformed the *custom CNN* in terms of **test accuracy** (*72.55% vs 36.00%*).\n",
    "   - This demonstrates the power of transfer learning, leveraging pre-trained weights on a large dataset.\n",
    "\n",
    "2. **Generalization:**\n",
    "   - The *MobileNetV2 model* shows better generalization to the test set, with **test accuracy** (*72.55%*) higher than **final training accuracy** (*54.64%*).\n",
    "   - However, the large gap between **precision** (*87.50%*) and **recall** (*13.73%*) in the *MobileNetV2 model* suggests it might be overly conservative in its predictions.\n",
    "\n",
    "3. **Training Stability:**\n",
    "   - The *custom CNN* showed more stable training, with gradual improvements in both training and validation metrics.\n",
    "   - The *MobileNetV2-based model* had more erratic validation performance, particularly in accuracy, which could indicate issues with the validation set or overfitting.\n",
    "\n",
    "4. **Mobile Deployment Potential:**\n",
    "   - The *MobileNetV2-based model* is specifically designed for mobile deployment, making it more suitable for this purpose.\n",
    "   - Its significantly better performance also makes it a more viable candidate for real-world application.\n",
    "\n",
    "5. **Learning Efficiency:**\n",
    "   - The *MobileNetV2-based model* achieved better performance in the same number of epochs, likely due to the advantage of pre-trained weights.\n",
    "\n",
    "6. **Overfitting Concerns:**\n",
    "   - Both models show signs of overfitting, but it's more pronounced in the *MobileNetV2 model*, particularly in the later epochs.\n",
    "\n",
    "7. **Room for Improvement:**\n",
    "   - Both models, especially the *custom CNN*, have significant room for improvement given the relatively low accuracies.\n",
    "   - The *MobileNetV2-based model's* imbalance between precision and recall suggests that class balancing or threshold adjustment might be beneficial.\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "1. The transfer learning approach with MobileNetV2 (Section 2) is superior in terms of performance and suitability for mobile deployment.\n",
    "2. However, both models could benefit from further optimization, potentially including:\n",
    "   - More extensive data augmentation\n",
    "   - Addressing class imbalance issues\n",
    "   - Fine-tuning hyperparameters\n",
    "   - Potentially increasing model complexity for the custom CNN or unfreezing more layers in the MobileNetV2 model\n",
    "3. The unusual behavior in the MobileNetV2 model's validation accuracy warrants further investigation into the validation set and training process.\n",
    "4. For practical deployment, the MobileNetV2 model is the better choice, but efforts should be made to improve its recall without significantly sacrificing precision.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
