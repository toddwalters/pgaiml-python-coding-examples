{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/toddwalters/pgaiml-python-coding-examples/blob/main/deep-learning/projects/automatingPortOperations/1714053668_ToddWalters_project_automating_port_operations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bY8iESXrFnl4",
    "outputId": "127ead91-357b-45ab-ada8-9eaedadcb38f"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXqTWV3iFnl4"
   },
   "source": [
    "# <a id='toc1_'></a>[**Automating Port Operations**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQ7XucjeFnl5"
   },
   "source": [
    "-----------------------------\n",
    "## <a id='toc1_1_'></a>[**Context**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "Marina Pier Inc. is leveraging technology to automate their operations on the San Francisco port.\n",
    "The companyâ€™s management has set out to build a bias-free/ corruption-free automatic system that reports & avoids faulty situations caused by human error.\n",
    "\n",
    "-----------------------------\n",
    "## <a id='toc1_2_'></a>[**Objectives**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "Marina Pier wants to use Deep Learning techniques to build an automatic reporting system that recognizes the boat. The company is also looking to use a transfer learning approach of any lightweight pre-trained model in order to deploy in mobile devices.\n",
    "As a deep learning engineer, your task is to:\n",
    "\n",
    "1.\tBuild a CNN network to classify the boat.\n",
    "\n",
    "2.\tBuild a lightweight model with the aim of deploying the solution on a mobile device using transfer learning. You can use any lightweight pre-trained model as the initial (first) layer. MobileNetV2 is a popular lightweight pre-trained model built using Keras API.\n",
    "\n",
    "-----------------------------\n",
    "## <a id='toc1_3_'></a>[**Dataset**](#toc0_)\n",
    "-----------------------------\n",
    "\n",
    "**boat_type_classification_dataset.zip**\n",
    "\n",
    "The dataset contains images of 9 types of boats. It contains a total of 1162 images. The training images are provided in the directory of the specific class itself.\n",
    "Classes:\n",
    "\n",
    "- ferry_boat\n",
    "- gondola\n",
    "- sailboat\n",
    "- cruise_ship\n",
    "- kayak\n",
    "- inflatable_boat\n",
    "- paper_boat\n",
    "- buoy\n",
    "- freight_boat\n",
    "\n",
    "\n",
    "-----------------------------------\n",
    "## <a id='toc1_4_'></a>[**Analysis Steps to Perform**](#toc0_)\n",
    "-----------------------------------\n",
    "1.\tBuild a CNN network to classify the boat.\n",
    "\n",
    "    1.1.\tSplit the dataset into train and test in the ratio 80:20, with shuffle and random state=43.\n",
    "\n",
    "    1.2.\tUse tf.keras.preprocessing.image_dataset_from_directory to load the train and test datasets. This function also supports data normalization.*(Hint: image_scale=1./255)*\n",
    "\n",
    "    1.3.\tLoad train, validation and test dataset in batches of 32 using the function initialized in the above step.\n",
    "\n",
    "    1.4.\tBuild a CNN network using Keras with the following layers\n",
    "\n",
    "       - Cov2D with 32 filters, kernel size 3,3, and activation relu, followed by MaxPool2D\n",
    "\n",
    "       - Cov2D with 32 filters, kernel size 3,3, and activation relu, followed by MaxPool2D\n",
    "\n",
    "       - GLobalAveragePooling2D layer\n",
    "\n",
    "       - Dense layer with 128 neurons and activation relu\n",
    "\n",
    "       - Dense layer with 128 neurons and activation relu\n",
    "    \n",
    "       - Dense layer with 9 neurons and activation softmax.\n",
    "\n",
    "    1.5.\tCompile the model with Adam optimizer, categorical_crossentropy loss, and with metrics accuracy, precision, and recall.\n",
    "\n",
    "    1.6.\tTrain the model for 20 epochs and plot training loss and accuracy against epochs.\n",
    "\n",
    "    1.7.\tEvaluate the model on test images and print the test loss and accuracy.\n",
    "\n",
    "    1.8.\tPlot heatmap of the confusion matrix and print classification report.\n",
    "\n",
    "2.\tBuild a lightweight model with the aim of deploying the solution on a mobile device using transfer learning. You can use any lightweight pre-trained model as the initial (first) layer. MobileNetV2 is a popular lightweight pre-trained model built using Keras API.\n",
    "\n",
    "    2.1.\tSplit the dataset into train and test datasets in the ration 70:30, with shuffle and random state=1.\n",
    "\n",
    "    2.2.\tUse tf.keras.preprocessing.image_dataset_from_directory to load the train and test datasets. This function also supports data normalization.*(Hint: Image_scale=1./255)*\n",
    "\n",
    "    2.3.\tLoad train, validation and test datasets in batches of 32 using the function initialized in the above step.\n",
    "\n",
    "    2.4.\tBuild a CNN network using Keras with the following layers.\n",
    "\n",
    "      - Load MobileNetV2 - Light Model as the first layer *(Hint: Keras API Doc)*\n",
    "\n",
    "      - GLobalAveragePooling2D layer\n",
    "\n",
    "      - Dropout(0.2)\n",
    "\n",
    "      - Dense layer with 256 neurons and activation relu\n",
    "\n",
    "      - BatchNormalization layer\n",
    "\n",
    "      - Dropout(0.1)\n",
    "\n",
    "      - Dense layer with 128 neurons and activation relu\n",
    "\n",
    "      - BatchNormalization layer\n",
    "\n",
    "      - Dropout(0.1)\n",
    "\n",
    "      - Dense layer with 9 neurons and activation softmax\n",
    "\n",
    "    2.5.\tCompile the model with Adam optimizer, categorical_crossentropy loss, and metrics accuracy, Precision, and Recall.\n",
    "\n",
    "    2.6.\tTrain the model for 50 epochs and Early stopping while monitoring validation loss.\n",
    "\n",
    "    2.7.\tEvaluate the model on test images and print the test loss and accuracy.\n",
    "\n",
    "    2.8.\tPlot Train loss Vs Validation loss and Train accuracy Vs Validation accuracy.\n",
    "    \n",
    "3.\tCompare the results of both models built in steps 1 and 2 and state your observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rHz_5EEfFnl5"
   },
   "source": [
    "## <a id='toc1_5_'></a>[**1.0 Build A CNN Network To Classify A Boat**](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWqVKXKtFnl5"
   },
   "source": [
    "**Setup: Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vtYfv5plFnl5"
   },
   "outputs": [],
   "source": [
    "# !pip install matplotlib seaborn scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4kxMwRpFnl6"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set the path to your dataset\n",
    "#data_dir = pathlib.Path(\"boat_type_classification_dataset\")\n",
    "data_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/datasets/boat_type_classification_dataset\")\n",
    "\n",
    "# Set common parameters\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dNDE8nqrFnl6"
   },
   "source": [
    "### <a id='toc1_5_1_'></a>[**1.1 Split the dataset into train and test in the ratio 80:20, with shuffle and random state=43**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yq_ODKMLFnl6",
    "outputId": "7233cc95-bfde-4f17-a2aa-9f53e103cb75"
   },
   "outputs": [],
   "source": [
    "# Load and split the full dataset\n",
    "full_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.2,\n",
    "    subset=\"both\",\n",
    "    seed=43,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=None,  # Load without batching initially\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Split the full dataset into train and test\n",
    "train_ds, test_ds = full_ds\n",
    "\n",
    "# Store class names\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(\"Number of training samples:\", tf.data.experimental.cardinality(train_ds))\n",
    "print(\"Number of test samples:\", tf.data.experimental.cardinality(test_ds))\n",
    "print(\"Class names:\", class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rv79ZXhNFnl6"
   },
   "source": [
    "#### <a id='toc1_5_1_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.1** is responsible for loading the dataset and splitting it into training and testing sets.\n",
    "\n",
    "- We use `tf.keras.preprocessing.image_dataset_from_directory` to load images directly from the filesystem. This function is convenient as it handles the file reading and label assignment automatically.\n",
    "- We set `validation_split=0.2` and `subset=\"both\"` to get both training and testing sets in an 80:20 ratio.\n",
    "- `seed=43` ensures reproducibility of the random split.\n",
    "- `shuffle=True` randomizes the order of the samples, which is important for training neural networks.\n",
    "- We set `batch_size=batch_size` setting the batch size here means that our dataset will be divided into batches of 32 images each. This is important for several reasons:\n",
    "  - *Memory Efficiency:* Processing 32 images at a time is more memory-efficient than loading the entire dataset at once, especially for large datasets.\n",
    "  - *Training Dynamics:* Batch size affects the dynamics of model training. A batch size of 32 is often a good default, balancing between the noisy gradients of very small batches and the longer computation time of larger batches.\n",
    "  - *Consistency:* By setting the batch size here, we ensure that all parts of our pipeline (data loading, augmentation, model training) use the same batch size.\n",
    "- The `image_size` parameter resizes all images to a consistent size, which is necessary for batch processing in neural networks.\n",
    "\n",
    "#### <a id='toc1_5_1_2_'></a>[Why it's important:](#toc0_)\n",
    "\n",
    "- Properly splitting the data ensures we have separate sets for training and evaluation, which is crucial for assessing the model's performance on unseen data.\n",
    "- The 80:20 split is a common ratio that balances having enough training data while still retaining a significant portion for testing.\n",
    "- Shuffling the data helps prevent any bias that might occur from the order of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8APeaLRiFnl6"
   },
   "source": [
    "### <a id='toc1_5_2_'></a>[**1.2 Use tf.keras.preprocessing.image_dataset_from_directory to load the train and test datasets.**](#toc0_)\n",
    "\n",
    "This function also supports data normalization. *(Hint: image_scale=1./255)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_PMaeJv0Fnl6",
    "outputId": "4c98f748-b9cd-4184-8841-65820577d2c1"
   },
   "outputs": [],
   "source": [
    "def normalize_img(image, label):\n",
    "    \"\"\"Normalizes images: `uint8` -> `float32`.\"\"\"\n",
    "    return tf.cast(image, tf.float32) / 255.0, label\n",
    "\n",
    "# Apply normalization to the datasets\n",
    "train_ds = train_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "# Function to check normalization\n",
    "def check_normalization(dataset):\n",
    "    for images, _ in dataset.take(1):\n",
    "        print(\"Image data range:\", tf.reduce_min(images).numpy(), \"to\", tf.reduce_max(images).numpy())\n",
    "\n",
    "print(\"Checking train dataset normalization:\")\n",
    "check_normalization(train_ds)\n",
    "print(\"\\nChecking test dataset normalization:\")\n",
    "check_normalization(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O31FVFRrFnl6"
   },
   "source": [
    "#### <a id='toc1_5_2_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.2** is performing the following:\n",
    "\n",
    "- Focuses on normalizing the image data and verifying that the normalization was applied correctly.\n",
    "- Defines a `normalize_img` function that converts the image data from integers in the range [0, 255] to floating-point numbers in the range [0, 1].\n",
    "- Applies this normalization to both the training and testing datasets using the map function.\n",
    "- The `check_normalization` function safely checks the range of values in the normalized datasets.\n",
    "\n",
    "#### <a id='toc1_5_2_2_'></a>[Why it's important](#toc0_)\n",
    "\n",
    "- Normalization is crucial for neural network training. It helps the model converge faster and can lead to better performance.\n",
    "- Scaling the input to a standard range (like [0, 1]) ensures that all features contribute equally to the model's learning process.\n",
    "- Checking the normalization helps verify that our preprocessing steps are working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlYV8GTiFnl6"
   },
   "source": [
    "### <a id='toc1_5_3_'></a>[**1.3 Load train, validation and test dataset in batches of 32 using the function initialized in the above step.**](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EM9L3AC4Fnl6",
    "outputId": "47cf883b-bcd5-42f8-dc19-664015e0d1fb"
   },
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset, is_training=False):\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(buffer_size=1000)\n",
    "\n",
    "    dataset = dataset.batch(batch_size)\n",
    "\n",
    "    if is_training:\n",
    "        data_augmentation = tf.keras.Sequential([\n",
    "            tf.keras.layers.RandomFlip('horizontal'),\n",
    "            tf.keras.layers.RandomRotation(0.2),\n",
    "        ])\n",
    "        dataset = dataset.map(lambda x, y: (data_augmentation(x, training=True), y),\n",
    "                              num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "    return dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = prepare_dataset(train_ds, is_training=True)\n",
    "test_ds = prepare_dataset(test_ds)\n",
    "\n",
    "val_ds = test_ds.take(tf.data.experimental.cardinality(test_ds) // 2)\n",
    "test_ds = test_ds.skip(tf.data.experimental.cardinality(test_ds) // 2)\n",
    "\n",
    "print(\"Number of training batches:\", tf.data.experimental.cardinality(train_ds))\n",
    "print(\"Number of validation batches:\", tf.data.experimental.cardinality(val_ds))\n",
    "print(\"Number of test batches:\", tf.data.experimental.cardinality(test_ds))\n",
    "\n",
    "def one_hot_encode(image, label):\n",
    "    return image, tf.one_hot(tf.cast(label, tf.int32), depth=num_classes)\n",
    "\n",
    "train_ds = train_ds.map(one_hot_encode)\n",
    "val_ds = val_ds.map(one_hot_encode)\n",
    "test_ds = test_ds.map(one_hot_encode)\n",
    "\n",
    "# Print an example batch to verify the shape\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Image batch shape:\", images.shape)\n",
    "    print(\"Label batch shape:\", labels.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c58fC7R7Fnl6"
   },
   "source": [
    "#### <a id='toc1_5_3_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.3** prepares the datasets for training by applying several important transformations and encodings.\n",
    "\n",
    "1. **Dataset Preparation:**\n",
    "   \n",
    "   - The `prepare_dataset` function applies shuffling (for training data), batching, and data augmentation (for training data).\n",
    "   - Datasets are split into train, validation, and test sets.\n",
    "\n",
    "2. **One-Hot Encoding:**\n",
    "\n",
    "   - After the initial preparation, we apply one-hot encoding to the labels in all datasets (train, validation, and test).\n",
    "   - The `one_hot_encode` function converts integer labels to one-hot encoded vectors.\n",
    "\n",
    "3. **Verification:**\n",
    "\n",
    "   - We print the shapes of images and labels from a batch to verify the encoding and overall data structure.\n",
    "\n",
    "4. **Batch Retrieval:**\n",
    "\n",
    "   - A function is provided to safely get a batch from the dataset, which is useful for inspection and debugging.\n",
    "\n",
    "#### <a id='toc1_5_3_2_'></a>[Why this is important](#toc0_)\n",
    "\n",
    "1. **Data Preparation:**\n",
    "\n",
    "   - Proper dataset preparation ensures that the model receives data in the correct format and with appropriate preprocessing.\n",
    "   - Shuffling the training data helps prevent the model from learning any unintended patterns based on the order of samples.\n",
    "   - Batching allows for efficient processing during training.\n",
    "   - Data augmentation helps increase the diversity of the training data, potentially improving model generalization.\n",
    "\n",
    "2. **One-Hot Encoding:**\n",
    "\n",
    "   - One-hot encoding is crucial for multi-class classification problems when using categorical crossentropy loss.\n",
    "   - It converts integer labels (e.g., 0, 1, 2) into vector form (e.g., [1,0,0], [0,1,0], [0,0,1]), which is necessary for the model's output layer and loss function.\n",
    "   - This encoding ensures that the model's output (a probability distribution over classes) matches the format of the labels.\n",
    "\n",
    "3. **Verification:**\n",
    "\n",
    "   - Checking the shapes of the images and labels after preprocessing is vital to catch any issues early.\n",
    "   - It confirms that the one-hot encoding has been applied correctly and that the data dimensions match what the model expects.\n",
    "\n",
    "4. **Batch Retrieval:**\n",
    "\n",
    "   - Having a safe method to retrieve batches allows for easy inspection of the data at various points in the pipeline.\n",
    "   - This can be crucial for debugging and ensuring that the data fed into the model is correct.\n",
    "\n",
    "\n",
    "By performing these steps, we ensure that our data is properly prepared, encoded, and verified before being used for model training, which is crucial for the success and efficiency of the subsequent training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "INlIP1QtFnl6"
   },
   "source": [
    "### <a id='toc1_5_4_'></a>[**1.4.\tBuild a CNN network using Keras with the following layers**](#toc0_)\n",
    "- Cov2D with 32 filters, kernel size 3,3, and activation relu, followed by MaxPool2D\n",
    "\n",
    "- Cov2D with 32 filters, kernel size 3,3, and activation relu, followed by MaxPool2D\n",
    "\n",
    "- GLobalAveragePooling2D layer\n",
    "\n",
    "- Dense layer with 128 neurons and activation relu\n",
    "\n",
    "- Dense layer with 128 neurons and activation relu\n",
    "- Dense layer with 9 neurons and activation softmax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k8zXWIUeFnl6",
    "outputId": "33125315-99f0-472f-b36a-5dd05af431b2"
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hdpUlQ0TFnl6"
   },
   "source": [
    "#### <a id='toc1_5_4_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.4** defines and builds the CNN (Convolutional Neural Network) as specified. Here's a breakdown of the architecture:\n",
    "\n",
    "1. **First Convolutional Layer:**\n",
    "\n",
    "   - 32 filters with a 3x3 kernel size\n",
    "   - ReLU activation function\n",
    "   - Followed by a 2x2 MaxPooling layer\n",
    "\n",
    "2. **Second Convolutional Layer:**\n",
    "\n",
    "   - 32 filters with a 3x3 kernel size\n",
    "   - ReLU activation function\n",
    "   - Followed by a 2x2 MaxPooling layer\n",
    "\n",
    "3. **Global Average Pooling Layer:**\n",
    "\n",
    "   - Reduces the spatial dimensions of the feature maps to a single value per filter\n",
    "\n",
    "4. **First Dense Layer:**\n",
    "\n",
    "   - 128 neurons with ReLU activation\n",
    "\n",
    "5. **Second Dense Layer:**\n",
    "\n",
    "   - 128 neurons with ReLU activation\n",
    "\n",
    "6. **Output Layer**:\n",
    "\n",
    "   - 9 neurons (one for each class) with softmax activation\n",
    "\n",
    "\n",
    "The `build_cnn_model` function takes the input shape and number of classes as parameters, making it flexible for different image sizes and number of categories.\n",
    "\n",
    "We then use this function to create our model, passing in the image dimensions and number of classes that we determined from our dataset.\n",
    "\n",
    "Finally, we print a summary of the model, which will show the layers, their output shapes, and the total number of parameters in the network.\n",
    "\n",
    "This CNN architecture is designed to:\n",
    "\n",
    "- Extract features from the images using convolutional layers\n",
    "- Reduce spatial dimensions and computational load using max pooling\n",
    "- Convert the 2D feature maps to a 1D feature vector using global average pooling\n",
    "- Make the final classification using fully connected (dense) layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_YkQ8cjwFnl7"
   },
   "source": [
    "### <a id='toc1_5_5_'></a>[1.5.\tCompile the model with Adam optimizer, categorical_crossentropy loss, and with metrics accuracy, precision, and recall.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHaHAksVFnl7",
    "outputId": "5a3d9d12-4c28-445e-bbab-f7c30a6b31e3"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy',\n",
    "             tf.keras.metrics.Precision(name='precision'),\n",
    "             tf.keras.metrics.Recall(name='recall')]\n",
    ")\n",
    "\n",
    "print(\"Model compiled successfully with the following configuration:\")\n",
    "print(f\"Optimizer: Adam\")\n",
    "print(f\"Loss function: Categorical Crossentropy\")\n",
    "print(f\"Metrics: Accuracy, Precision, Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Op_xBoDFnl7"
   },
   "source": [
    "#### <a id='toc1_5_5_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.5** compiles the CNN model we built in the previous section. Here's a breakdown of what each part does:\n",
    "\n",
    "1. **Optimizer: Adam**\n",
    "\n",
    "    - We use the Adam optimizer, which is an adaptive learning rate optimization algorithm.\n",
    "    - Adam is widely used because it combines the benefits of two other extensions of stochastic gradient descent: AdaGrad and RMSProp.\n",
    "    - It's generally a good default choice for many deep learning tasks.\n",
    "\n",
    "2. **Loss Function: Categorical Crossentropy**\n",
    "\n",
    "    - We use 'categorical_crossentropy' as our loss function.\n",
    "    - This is appropriate for multi-class classification problems where each sample belongs to exactly one class.\n",
    "    - It measures the dissimilarity between the predicted probability distribution and the true distribution.\n",
    "\n",
    "3. **Metrics: Accuracy, Precision, and Recall**\n",
    "\n",
    "    - *Accuracy:* Measures the proportion of correct predictions (both true positives and true negatives) among the total number of cases examined.\n",
    "    - *Precision:* Measures the proportion of true positive predictions among all positive predictions. It answers the question: \"Of all the samples predicted as positive, how many actually are positive?\"\n",
    "    - *Recall:* Measures the proportion of true positive predictions among all actual positive samples. It answers the question: \"Of all the actual positive samples, how many were correctly identified?\"\n",
    "\n",
    "#### <a id='toc1_5_5_2_'></a>[Why these choices are important](#toc0_)\n",
    "\n",
    "- Adam optimizer is often a good starting point as it adapts the learning rate during training, which can lead to faster convergence.\n",
    "- Categorical crossentropy is the standard loss function for multi-class classification problems.\n",
    "- Using multiple metrics (accuracy, precision, and recall) provides a more comprehensive evaluation of the model's performance, especially if the classes are imbalanced.\n",
    "- This code block compiles the CNN model we built in the previous section. Here's a breakdown of what each part does:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xB2c7fj3Fnl7"
   },
   "source": [
    "### <a id='toc1_5_6_'></a>[1.6.\tTrain the model for 20 epochs and plot training loss and accuracy against epochs.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qXK9q7A-Fnl7",
    "outputId": "0a32efee-90bb-4372-d1c7-32ca11803499"
   },
   "outputs": [],
   "source": [
    "# Check the shape of a batch from the training dataset\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Shape of images in a batch:\", images.shape)\n",
    "    print(\"Shape of labels in a batch:\", labels.shape)\n",
    "\n",
    "# Print the model summary again\n",
    "model.summary()\n",
    "\n",
    "# Check the number of classes\n",
    "print(\"Number of classes:\", len(class_names))\n",
    "\n",
    "# Check if labels are one-hot encoded\n",
    "if len(labels.shape) == 2 and labels.shape[1] > 1:\n",
    "    print(\"Labels are one-hot encoded\")\n",
    "else:\n",
    "    print(\"Labels are not one-hot encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9iwC2UxaFnl7",
    "outputId": "b74b511f-65fd-4f8f-e905-bf9ba6aae39a"
   },
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=20\n",
    ")\n",
    "\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='Training Loss')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Plot the training history\n",
    "plot_training_history(history)\n",
    "\n",
    "# Print final training and validation metrics\n",
    "print(\"Final training accuracy: {:.2f}%\".format(history.history['accuracy'][-1] * 100))\n",
    "print(\"Final validation accuracy: {:.2f}%\".format(history.history['val_accuracy'][-1] * 100))\n",
    "print(\"Final training loss: {:.4f}\".format(history.history['loss'][-1]))\n",
    "print(\"Final validation loss: {:.4f}\".format(history.history['val_loss'][-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IbirVtFOFnl7"
   },
   "source": [
    "#### <a id='toc1_5_6_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.6** trains the model and visualizes the training progress. Here's a breakdown of what each part does:\n",
    "\n",
    "1. **Training the model:**\n",
    "\n",
    "   - We use the fit() method to train the model.\n",
    "   - `train_ds` is used as the training data.\n",
    "   - `val_ds` is used as the validation data.\n",
    "   - We train for 20 epochs as specified.\n",
    "   - The `verbose=1` parameter gives us detailed output for each epoch.\n",
    "\n",
    "2. **Plotting the training history:**\n",
    "\n",
    "   - We define a function plot_training_history() that creates two subplots:\n",
    "\n",
    "      - **Model Accuracy:** Shows how the training and validation accuracy change over epochs.\n",
    "      - **Model Loss:** Shows how the training and validation loss change over epochs.\n",
    "\n",
    "   - The plots use different colors for training and validation metrics, making it easy to compare them.\n",
    "\n",
    "3. **Printing final metrics:**\n",
    "\n",
    "   - We print the final training and validation accuracy and loss.\n",
    "   - This gives us a quick summary of the model's performance at the end of training.\n",
    "\n",
    "#### <a id='toc1_5_6_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Training Progress:**\n",
    "   - Training accuracy increased from 32.80% (Epoch 1) to 42.80% (Epoch 20).\n",
    "   - Training loss decreased from 1.9155 (Epoch 1) to 1.6057 (Epoch 20).\n",
    "   - Validation accuracy fluctuated but generally improved from 31.25% (Epoch 1) to 37.50% (Epoch 20).\n",
    "   - Validation loss overall decreased from 1.8069 (Epoch 1) to 1.6700 (Epoch 20).\n",
    "\n",
    "2. **Precision and Recall:**\n",
    "   - Training precision and recall generally improved over time, but remained inconsistent.\n",
    "   - Validation precision and recall were highly volatile, with some epochs showing 0.0000 for both metrics.\n",
    "\n",
    "4. **Overfitting:**\n",
    "   - There's a consistent gap between training and validation accuracy, indicating some degree of overfitting.\n",
    "\n",
    "5. **Instability:**\n",
    "   - The validation metrics show significant fluctuations across epochs, suggesting instability in the model's performance on unseen data.\n",
    "\n",
    "#### <a id='toc1_5_6_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. **Limited Learning:** The model has learned to classify the boats to some extent, but its performance is still relatively poor for a 9-class classification task. An accuracy of around 40% suggests there's significant room for improvement.\n",
    "\n",
    "2. **Overfitting:** The consistent gap between training and validation metrics suggests the model may be overfitting to the training data. This could be addressed by:\n",
    "   - Increasing regularization (e.g., dropout, L2 regularization)\n",
    "   - Collecting more training data\n",
    "   - Simplifying the model architecture\n",
    "\n",
    "3. **Data Issues:** The extreme fluctuations in validation precision and recall, including zero values, suggest potential issues with the validation set. This could be due to:\n",
    "   - Class imbalance in the dataset\n",
    "   - Small validation set size leading to high variance\n",
    "   - Potential data leakage or preprocessing issues\n",
    "\n",
    "5. **Instability:** The fluctuations in validation metrics suggest that the model's performance is not consistent across different subsets of the data, which could indicate issues with generalization.\n",
    "\n",
    "6. **Need for Improvement:** Given the low accuracy and instability, consider:\n",
    "   - Experimenting with different model architectures\n",
    "   - Applying more aggressive data augmentation\n",
    "   - Using transfer learning with a pre-trained model\n",
    "   - Addressing potential class imbalance issues\n",
    "\n",
    "7. **Further Analysis Required:** It would be beneficial to:\n",
    "   - Examine the confusion matrix to understand which classes are most problematic\n",
    "   - Analyze misclassified samples to gain insights into the model's weaknesses\n",
    "   - Investigate the distribution of classes across train and validation sets\n",
    "\n",
    "While the model shows some learning, its performance is suboptimal and unstable. Significant improvements in data preparation, model architecture, and training approach are necessary to create a reliable boat classification system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QXmcwa4DFnl7"
   },
   "source": [
    "### <a id='toc1_5_7_'></a>[1.7.\tEvaluate the model on test images and print the test loss and accuracy.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2rVae9BuFnl7",
    "outputId": "e7d751e0-2db6-4875-9155-77390e884f85"
   },
   "outputs": [],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_ds)\n",
    "\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test precision: {test_precision:.4f}\")\n",
    "print(f\"Test recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cg-nJnxaFnl7"
   },
   "source": [
    "#### <a id='toc1_5_7_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.7** is evaluating the model with test images and determining the test loss and accuracy.  Specifically:\n",
    "\n",
    "1. Uses the `model.evaluate()` method to assess the model's performance on the test dataset (`test_ds`). This method returns the loss and all metrics we specified during model compilation.\n",
    "2. Caculates and prints the test loss, accuracy, precision, and recall. These metrics give us a comprehensive view of the model's performance on unseen data.\n",
    "3. Compares the test results with the final training and validation results provided. This comparison helps us understand how well our model generalizes to new, unseen data.\n",
    "\n",
    "#### <a id='toc1_5_7_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Test Performance:**\n",
    "   - **Test loss:** 1.7490\n",
    "   - **Test accuracy:** 33.65%\n",
    "   - **Test recall:** 11.54%\n",
    "\n",
    "2. **Comparison with Training and Validation:**\n",
    "   - Training accuracy (42.80%) > Validation accuracy (37.50%) > Test accuracy (31.73%)\n",
    "   - Training loss (1.6057) < Validation loss (1.6700) < Test loss (1.7490)\n",
    "\n",
    "3. **Precision and Recall:**\n",
    "   - Test precision (42.86%) is higher as compared to the accuracy (33.65%).\n",
    "    - The higher precision indicates that when the model makes a positive prediction, it's more likely to be correct.\n",
    "    - The lower accuracy suggests it's missing many correct classifications overall.\n",
    "    - This pattern often indicates a conservative model. It's making fewer positive predictions, but those it does make are more often correct.\n",
    "    - This disparity can sometimes occur in imbalanced datasets. The model might be performing well on some classes (leading to higher precision) but poorly on others (lowering overall accuracy).\n",
    "   - Test recall (11.54%) is very low.\n",
    "\n",
    "#### <a id='toc1_5_7_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. **Overfitting:** The significant drop in accuracy from training (42.80%) to test (33.65%) strongly suggests that the model is overfitting to the training data. It's not generalizing well to unseen data.\n",
    "\n",
    "2. **Poor Generalization:** The test accuracy of 33.65% indicates that the model's performance on new, unseen data is poor. For a multi-class classification problem, this is only marginally better than random guessing, depending on the number of classes.\n",
    "\n",
    "3. **Precision-Recall Tradeoff:** The higher precision (42.86%) coupled with  low recall (11.54%) suggests that the model is being conservative in its predictions. It's making very few positive predictions, but when it does, it's often correct. However, it's missing the vast majority of positive cases.\n",
    "\n",
    "4. **Class Imbalance:** The discrepancy between accuracy and precision might indicate class imbalance in the dataset. The model might be performing well on some classes but poorly on others.\n",
    "\n",
    "5. **Model Limitations:** The overall low performance across all metrics (accuracy, recall) indicates that the current model architecture or training approach is not suitable for this particular classification task.\n",
    "\n",
    "6. **Data Issues:** The consistent degradation of performance from training to validation to test sets might also point to potential issues with data distribution across these sets. There might be a mismatch in the distribution of classes or features.\n",
    "\n",
    "7. **Need for Model Improvement:**\n",
    "\n",
    "  Given the poor test performance, significant improvements are needed. This could include:\n",
    "   - Redesigning the model architecture\n",
    "   - Implementing more effective regularization techniques\n",
    "   - Using transfer learning with a pre-trained model\n",
    "   - Addressing potential class imbalance issues\n",
    "   - Collecting more diverse training data\n",
    "\n",
    "8. **Further Analysis Required:** It would be beneficial to:\n",
    "   - Examine the confusion matrix to understand which classes are most problematic\n",
    "   - Analyze misclassified samples to gain insights into the model's weaknesses\n",
    "   - Investigate the distribution of classes across train, validation, and test sets\n",
    "\n",
    "While the model showed some learning capacity during training, its poor performance on the test set indicates serious limitations in its current form. The next steps should focus on addressing overfitting, improving generalization, and potentially revisiting the fundamental approach to this classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFA2TqhyFnl7"
   },
   "source": [
    "### <a id='toc1_5_8_'></a>[1.8.\tPlot heatmap of the confusion matrix and print classification report.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3bVyVvFVFnl7",
    "outputId": "8b13d232-456c-4431-93f6-9056742bd449"
   },
   "outputs": [],
   "source": [
    "# Get predictions for the test dataset\n",
    "y_pred_probabilities = model.predict(test_ds)\n",
    "y_pred = np.argmax(y_pred_probabilities, axis=1)\n",
    "\n",
    "# Get true labels\n",
    "y_true = []\n",
    "for _, labels in test_ds:\n",
    "    y_true.extend(np.argmax(labels, axis=1))\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "print(\"Unique classes in true labels:\", np.unique(y_true))\n",
    "print(\"Unique classes in predictions:\", np.unique(y_pred))\n",
    "print(\"Class distribution in true labels:\", np.bincount(y_true))\n",
    "print(\"Class distribution in predictions:\", np.bincount(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "4zkwsGJOFnl7",
    "outputId": "ae78343c-6d43-4a57-d66c-38e1962f111d"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Now we can proceed with the confusion matrix and classification report\n",
    "print(\"Original class names:\", class_names)\n",
    "print(\"Number of original classes:\", len(class_names))\n",
    "print(\"Unique classes in true labels:\", np.unique(y_true))\n",
    "print(\"Unique classes in predictions:\", np.unique(y_pred))\n",
    "print(\"Number of unique classes in true labels:\", len(np.unique(y_true)))\n",
    "print(\"Number of unique classes in predictions:\", len(np.unique(y_pred)))\n",
    "\n",
    "# Get the union of classes present in both true labels and predictions\n",
    "all_present_classes = np.union1d(np.unique(y_true), np.unique(y_pred))\n",
    "present_class_names = [class_names[i] for i in all_present_classes if i < len(class_names)]\n",
    "\n",
    "print(\"Classes present in true labels or predictions:\", present_class_names)\n",
    "print(\"Number of present classes:\", len(present_class_names))\n",
    "\n",
    "# Generate classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=present_class_names, zero_division=0))\n",
    "\n",
    "# Plot confusion matrix\n",
    "def plot_confusion_matrix(y_true, y_pred, class_names):\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=range(len(class_names)))\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names,\n",
    "                yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_confusion_matrix(y_true, y_pred, present_class_names)\n",
    "\n",
    "# Calculate per-class accuracy\n",
    "cm = confusion_matrix(y_true, y_pred, labels=range(len(present_class_names)))\n",
    "\n",
    "def safe_divide(a, b):\n",
    "    return np.divide(a, b, out=np.zeros_like(a, dtype=float), where=b!=0)\n",
    "\n",
    "class_total = cm.sum(axis=1)\n",
    "class_correct = cm.diagonal()\n",
    "per_class_accuracy = safe_divide(class_correct, class_total)\n",
    "\n",
    "print(\"\\nPer-class Accuracy:\")\n",
    "for class_name, accuracy, correct, total in zip(present_class_names, per_class_accuracy, class_correct, class_total):\n",
    "    if total == 0:\n",
    "        print(f\"{class_name}: No samples\")\n",
    "    else:\n",
    "        print(f\"{class_name}: {accuracy:.2%} ({correct}/{total})\")\n",
    "\n",
    "# Overall accuracy\n",
    "overall_accuracy = np.sum(class_correct) / np.sum(class_total)\n",
    "print(f\"\\nOverall Accuracy: {overall_accuracy:.2%}\")\n",
    "\n",
    "# Class distribution in true labels\n",
    "print(\"\\nClass Distribution in Test Set:\")\n",
    "for class_name, total in zip(present_class_names, class_total):\n",
    "    print(f\"{class_name}: {total}\")\n",
    "\n",
    "# Class distribution in predictions\n",
    "pred_total = cm.sum(axis=0)\n",
    "print(\"\\nClass Distribution in Predictions:\")\n",
    "for class_name, total in zip(present_class_names, pred_total):\n",
    "    print(f\"{class_name}: {total}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tdz6oUcHFnl7"
   },
   "source": [
    "#### <a id='toc1_5_8_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 1.8** is performing a detailed analysis of the model's performance on the test dataset. Specifically, it's:\n",
    "\n",
    "1. Identifying the classes present in the true labels and predictions.\n",
    "2. Generating a classification report that includes precision, recall, and F1-score for each class.\n",
    "3. Calculating per-class accuracy.\n",
    "4. Displaying class distribution in the test set and model predictions.\n",
    "\n",
    "#### <a id='toc1_5_8_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Overprediction of gondolas**: The model predicted 43 instances as gondolas, while there were only 15 actual gondolas in the test set.\n",
    "2. **Poor performance on most classes**: The model completely fails to identify buoy, cruise_ship, ferry_boat, freight_boat, and inflatable_boat.\n",
    "3. **Moderate performance on gondolas**: 14 out of 15 gondolas were correctly classified, giving a high recall for this class.\n",
    "4. **Low precision for gondolas**: Despite high recall, the precision for gondolas is low due to many false positives.\n",
    "5. **Kayaks are often misclassified**: Only 5 out of 17 kayaks were correctly identified, with many being misclassified as gondolas.\n",
    "6. **Absence of sailboat in test set**: Despite being in the original classes, there are no sailboat samples in the test set.\n",
    "\n",
    "#### <a id='toc1_5_8_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. The model's performance is poor overall, with an accuracy of only 35.85%.\n",
    "2. There's a strong bias towards predicting gondolas, which skews the model's performance.\n",
    "3. The model fails entirely on several classes, indicating a need for significant improvements in feature extraction or model architecture.\n",
    "4. Class imbalance in the test set (and likely in the training set) is a major issue affecting the model's performance.\n",
    "5. The current model is not suitable for deployment in a real-world boat classification system due to its inconsistent and poor performance across classes.\n",
    "6. A complete overhaul of the modeling approach, including data preparation, model architecture, and training strategy, is necessary to create a reliable boat classification system.\n",
    "\n",
    "\n",
    "#### <a id='toc1_5_8_4_'></a>[Recommendations](#toc0_)\n",
    "\n",
    "1. **Address class imbalance**: Use techniques like oversampling, undersampling, or SMOTE to balance the training data.\n",
    "2. **Improve model generalization**: Use regularization techniques, increase training data diversity, or try transfer learning approaches.\n",
    "3. **Feature engineering**: Develop features that better distinguish between similar boat types, especially gondolas and kayaks.\n",
    "4. **Ensemble methods**: Combine multiple models to improve overall classification performance.\n",
    "5. **Data augmentation**: Increase the variety of training samples, especially for underrepresented classes.\n",
    "6. **Threshold adjustment**: Implement class-specific prediction thresholds to balance precision and recall for each class.\n",
    "7. **Error analysis**: Examine misclassified instances, especially those confused between gondolas and kayaks, to understand the model's weaknesses.\n",
    "\n",
    "The model's performance is poor and inconsistent across classes. Significant improvements in data preparation, model architecture, and training approach are necessary to create a reliable boat classification system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ss5CNjBFnl7"
   },
   "source": [
    "## <a id='toc1_6_'></a>[2.\tBuild a lightweight model with the aim of deploying the solution on a mobile device using transfer learning.](#toc0_)\n",
    "You can use any lightweight pre-trained model as the initial (first) layer. MobileNetV2 is a popular lightweight pre-trained model built using Keras API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jwflhV6SFnl7"
   },
   "source": [
    "**Setup: Import Necessary Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BsR7a30fFnl7"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Set the path to your dataset\n",
    "#data_dir = pathlib.Path(\"boat_type_classification_dataset\")\n",
    "data_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/datasets/boat_type_classification_dataset\")\n",
    "\n",
    "# Set common parameters\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O1kt24D1Fnl8"
   },
   "source": [
    "### <a id='toc1_6_1_'></a>[2.1.\tSplit the dataset into train and test datasets in the ration 70:30, with shuffle and random state=1.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q-VHKmZ_Fnl8",
    "outputId": "6ca8e081-4141-41a9-da8d-a846ab18349c"
   },
   "outputs": [],
   "source": [
    "# 2.1: Load and split the dataset\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=1,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=1,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Store class names before preprocessing\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "print(\"Class names:\", class_names)\n",
    "print(\"Number of classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMc_qxKsFnl8"
   },
   "source": [
    "#### <a id='toc1_6_1_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.1** is responsible for loading the dataset and splitting it into training and testing sets.\n",
    "\n",
    "- We use `tf.keras.preprocessing.image_dataset_from_directory` to load images directly from the filesystem. This function is convenient as it handles the file reading and label assignment automatically.\n",
    "- We set `validation_split=0.3` and `subset=\"both\"` to get both training and testing sets in an 70:30 ratio.\n",
    "- `seed=1` ensures reproducibility of the random split.\n",
    "- `shuffle=True` randomizes the order of the samples, which is important for training neural networks.\n",
    "- We set `batch_size=batch_size` setting the batch size here means that our dataset will be divided into batches of 32 images each. This is important for several reasons:\n",
    "  - *Memory Efficiency:* Processing 32 images at a time is more memory-efficient than loading the entire dataset at once, especially for large datasets.\n",
    "  - *Training Dynamics:* Batch size affects the dynamics of model training. A batch size of 32 is often a good default, balancing between the noisy gradients of very small batches and the longer computation time of larger batches.\n",
    "  - *Consistency:* By setting the batch size here, we ensure that all parts of our pipeline (data loading, augmentation, model training) use the same batch size.\n",
    "- The `image_size` parameter resizes all images to a consistent size, which is necessary for batch processing in neural networks.\n",
    "\n",
    "#### <a id='toc1_6_1_2_'></a>[Why It's Important](#toc0_)\n",
    "\n",
    "- Properly splitting the data ensures we have separate sets for training and evaluation, which is crucial for assessing the model's performance on unseen data.\n",
    "- The 70:30 split is a common ratio that balances having enough training data while still retaining a significant portion for testing.\n",
    "- Shuffling the data helps prevent any bias that might occur from the order of the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzT59d4SFnl8"
   },
   "source": [
    "### <a id='toc1_6_2_'></a>[2.2.\tUse tf.keras.preprocessing.image_dataset_from_directory to load the train and test datasets.](#toc0_)\n",
    "This function also supports data normalization.*(Hint: Image_scale=1./255)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wemeE-LDFnl8"
   },
   "outputs": [],
   "source": [
    "# 2.2: Prepare datasets (including normalization)\n",
    "def prepare_dataset(dataset):\n",
    "    # Normalize images\n",
    "    dataset = dataset.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "    # Convert labels to one-hot encoding\n",
    "    dataset = dataset.map(lambda x, y: (x, tf.one_hot(y, depth=num_classes)))\n",
    "    return dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = prepare_dataset(train_ds)\n",
    "test_ds = prepare_dataset(test_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lSFIO0KFFnl8"
   },
   "source": [
    "#### <a id='toc1_6_2_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.2** focuses on normalizing the image data and verifying that the normalization was applied correctly.\n",
    "\n",
    "- We define a `normalize_img` function that converts the image data from integers in the range [0, 255] to floating-point numbers in the range [0, 1].\n",
    "- We apply this normalization to both the training and testing datasets using the map function.\n",
    "- The `check_normalization` function safely checks the range of values in the normalized datasets.\n",
    "\n",
    "#### <a id='toc1_6_2_2_'></a>[Why It's Important](#toc0_)\n",
    "\n",
    "1. **Normalization:**\n",
    "   - Scaling the input data to a standard range (0-1) is crucial for neural networks. It helps the model converge faster during training and can lead to better overall performance.\n",
    "   - Normalized data ensures that all features contribute equally to the model's learning process, preventing features with larger scales from dominating the learning.\n",
    "\n",
    "2. **One-Hot Encoding:**\n",
    "   - One-hot encoding is necessary for multi-class classification problems when using categorical crossentropy loss.\n",
    "   - It converts categorical variables into a format that works better with classification algorithms and neural network architectures.\n",
    "\n",
    "3. **Performance Optimization:**\n",
    "   - The prefetch operation allows later elements to be prepared while the current element is being processed. This can significantly improve performance, especially on TPUs or multi-GPU systems.\n",
    "\n",
    "4. **Standardized Data Format:**\n",
    "   - By applying these transformations, the data is put into a standardized format that's ideal for training deep learning models. This ensures compatibility with the model architecture and loss functions.\n",
    "\n",
    "5. **Reproducibility and Consistency:**\n",
    "   - Applying the same preprocessing to both training and test datasets ensures consistency, which is crucial for fair evaluation of the model's performance.\n",
    "\n",
    "6. **Memory Efficiency:**\n",
    "   - Processing the data in this way allows for efficient memory usage, especially important when working with large datasets that might not fit entirely in memory.\n",
    "\n",
    "Section 2.2 is a critical data preparation step that normalizes the input, prepares the labels, and optimizes the data pipeline. These operations are fundamental to ensuring the model can learn effectively from the data and generalize well to new examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "669b3OdUFnl8"
   },
   "source": [
    "### <a id='toc1_6_3_'></a>[2.3.\tLoad train, validation and test datasets in batches of 32 using the function initialized in the above step.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BkSpwTvuFnl8",
    "outputId": "483167d9-5994-42b5-d3a8-aa780c997324"
   },
   "outputs": [],
   "source": [
    "# 2.3: Split test_ds into validation and test\n",
    "val_ds = test_ds.take(len(test_ds) // 2)\n",
    "test_ds = test_ds.skip(len(test_ds) // 2)\n",
    "\n",
    "print(\"Number of training batches:\", len(train_ds))\n",
    "print(\"Number of validation batches:\", len(val_ds))\n",
    "print(\"Number of test batches:\", len(test_ds))\n",
    "\n",
    "# Check the shape of our data\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Image shape:\", images.shape)\n",
    "    print(\"Label shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vwnHtTc0Fnl8"
   },
   "source": [
    "#### <a id='toc1_6_3_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.3** prepares the datasets for training by applying several important transformations and encodings. Here's a breakdown of the key steps:\n",
    "\n",
    "1. **Splitting the Data:**\n",
    "   The code is splitting the original dataset into three parts: training, validation, and test sets. This is a crucial step in machine learning workflows.\n",
    "\n",
    "2. **Checking Batch Sizes:**\n",
    "   The output shows:\n",
    "   - Number of training batches: 26\n",
    "   - Number of validation batches: 5\n",
    "   - Number of test batches: 6\n",
    "\n",
    "   This indicates how many batches of data are in each set when using a batch size of 32.\n",
    "\n",
    "3. **Verifying Data Shapes:**\n",
    "   The output also shows:\n",
    "   - Image shape: (32, 224, 224, 3)\n",
    "   - Label shape: (32, 9)\n",
    "\n",
    "#### <a id='toc1_6_3_2_'></a>[Why this is important](#toc0_)\n",
    "\n",
    "1. **Data Split:**\n",
    "   - Separating data into training, validation, and test sets is crucial for properly evaluating model performance.\n",
    "   - The training set is used to train the model.\n",
    "   - The validation set helps in tuning hyperparameters and preventing overfitting.\n",
    "   - The test set provides an unbiased evaluation of the final model's performance.\n",
    "\n",
    "2. **Batch Processing:**\n",
    "   - Processing data in batches (32 samples per batch here) is important for efficient training, especially with large datasets.\n",
    "   - It allows for stochastic gradient descent and related optimization algorithms to work effectively.\n",
    "   - The number of batches gives an idea of how many iterations will occur in each epoch during training.\n",
    "\n",
    "3. **Data Dimensions:**\n",
    "   - Knowing the image shape (32, 224, 224, 3) confirms:\n",
    "     * 32 images per batch\n",
    "     * Each image is 224x224 pixels\n",
    "     * 3 color channels (RGB)\n",
    "   - This is crucial for ensuring the data matches the expected input of the model architecture.\n",
    "\n",
    "4. **Label Information:**\n",
    "   - The label shape (32, 9) indicates:\n",
    "     * 32 labels per batch (matching the number of images)\n",
    "     * 9 classes in the classification task\n",
    "   - This confirms that the labels are properly one-hot encoded.\n",
    "\n",
    "5. **Memory Management:**\n",
    "   - Batching allows for efficient memory usage, especially important when working with large datasets that might not fit entirely in memory.\n",
    "\n",
    "6. **Training Process Insight:**\n",
    "   - Knowing the number of batches helps in understanding how long each epoch will take and how often the model will update its weights.\n",
    "\n",
    "7. **Validation Strategy:**\n",
    "   - The presence of validation batches indicates that the model will be evaluated during training, which is crucial for monitoring performance and preventing overfitting.\n",
    "\n",
    "8. **Reproducibility:**\n",
    "   - Clearly defined data splits and batch sizes contribute to the reproducibility of the experiment.\n",
    "\n",
    "Section 2.3 is setting up the data pipeline for training, validation, and testing. It ensures that the data is properly structured, split, and batched for efficient and effective model training and evaluation. The output provides crucial information about the dataset structure and preparation, which is fundamental for understanding the subsequent model training process and results interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YyS5F1cPFnl8"
   },
   "source": [
    "### <a id='toc1_6_4_'></a>[2.4.\tBuild a CNN network using Keras with the following layers.](#toc0_)\n",
    "     \n",
    "- Load MobileNetV2 - Light Model as the first layer *(Hint: Keras API Doc)*\n",
    "- GLobalAveragePooling2D layer\n",
    "- Dropout(0.2)\n",
    "- Dense layer with 256 neurons and activation relu\n",
    "- BatchNormalization layer\n",
    "- Dropout(0.1)\n",
    "- Dense layer with 128 neurons and activation relu\n",
    "- BatchNormalization layer\n",
    "- Dropout(0.1)\n",
    "- Dense layer with 9 neurons and activation softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_rDLd38pFnl8",
    "outputId": "046ba896-4365-4546-fe12-7dce49b6ed8c"
   },
   "outputs": [],
   "source": [
    "# 2.4: Build the model\n",
    "def build_model(num_classes):\n",
    "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(img_height, img_width, 3))\n",
    "    base_model.trainable = False\n",
    "\n",
    "    model = models.Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.1),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9wVcVeUjFnl8"
   },
   "source": [
    "#### <a id='toc1_6_4_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.4** creates the model and is focused on the following:\n",
    "\n",
    "1. **Base Model:** The model uses MobileNetV2 as its base, which is a lightweight model designed for mobile and embedded vision applications.\n",
    "2. **Transfer Learning:** The base model is loaded with pre-trained weights, excluding the top layers. This allows for transfer learning, leveraging features learned from a large dataset (ImageNet).\n",
    "3. **Custom Top Layers:** On top of the base model, several layers are added for fine-tuning to our specific classification task:\n",
    "    - Global Average Pooling to reduce spatial dimensions\n",
    "    - Dropout layers for regularization\n",
    "    - Dense layers for feature extraction and classification\n",
    "    - Batch Normalization layers to stabilize learning\n",
    "4. **Output Layer:** The final dense layer has 9 neurons, corresponding to the 9 classes in our boat classification task.\n",
    "\n",
    "#### <a id='toc1_6_4_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Model Size:**\n",
    "    - Total params: 2,621,513 (~10.00 MB)\n",
    "    - Trainable params: 362,761 (~1.38 MB)\n",
    "    - Non-trainable params: 2,258,752 (~8.62 MB)\n",
    "\n",
    "2. **Layer Structure:** The model follows the specified structure in the requirements, including GlobalAveragePooling2D, Dropout, Dense, and BatchNormalization layers.\n",
    "\n",
    "3. **Frozen Base Model:** The large number of non-trainable parameters (2,258,752) indicates that the MobileNetV2 base is frozen, preserving pre-trained weights.\n",
    "Customization: The trainable parameters (362,761) are in the custom top layers, allowing the model to adapt to our specific task.\n",
    "\n",
    "#### <a id='toc1_6_4_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. **Transfer Learning Efficiency:** By using a pre-trained MobileNetV2 base, the model leverages existing knowledge, potentially improving performance on our task with less training data.\n",
    "2. **Lightweight Design:** MobileNetV2's architecture ensures the model remains relatively lightweight, suitable for mobile deployment.\n",
    "3. **Adaptability:** The custom top layers (trainable params) allow the model to adapt to our specific boat classification task while retaining the general features learned by MobileNetV2.\n",
    "4. **Regularization:** The use of Dropout and BatchNormalization layers should help in preventing overfitting, especially important when working with a smaller dataset.\n",
    "5. **Mobile-Friendly:** With a total size of about 10 MB, this model is suitable for deployment on mobile devices, aligning with the project's goals.\n",
    "6. **Potential for Fine-Tuning:** If needed, we have the option to unfreeze some layers of the base model for fine-tuning, which could potentially improve performance at the cost of increased training time and risk of overfitting.\n",
    "\n",
    "Overall, this model architecture appears well-suited for the task of boat classification on mobile devices, balancing the benefits of transfer learning with the need for a lightweight, deployable model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2gmn644bFnl8"
   },
   "source": [
    "### <a id='toc1_6_5_'></a>[2.5.\tCompile the model with Adam optimizer, categorical_crossentropy loss, and metrics accuracy, Precision, and Recall.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fgfJ208jFnl8"
   },
   "outputs": [],
   "source": [
    "# 2.5: Compile the model\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uX6nmpTDFnl8"
   },
   "source": [
    "#### <a id='toc1_6_5_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.5** is focused on compiling the model. Here's the code for this section:\n",
    "\n",
    "1. **Model Compilation:**\n",
    "   The `compile` method is called on the model, which prepares the model for training. This step is crucial as it defines several key aspects of the training process.\n",
    "\n",
    "2. **Optimizer Selection:**\n",
    "   - The Adam optimizer is used here.\n",
    "   - Adam (Adaptive Moment Estimation) is an advanced optimization algorithm that adapts the learning rate for each parameter.\n",
    "   - It's generally a good default choice for many deep learning tasks due to its efficiency and good performance.\n",
    "\n",
    "3. **Loss Function:**\n",
    "   - 'categorical_crossentropy' is specified as the loss function.\n",
    "   - This is appropriate for multi-class classification problems where the classes are mutually exclusive (each image belongs to only one class).\n",
    "   - It measures the dissimilarity between the predicted probability distribution and the true distribution (one-hot encoded labels).\n",
    "\n",
    "4. **Evaluation Metrics:**\n",
    "   Three metrics are specified for evaluation:\n",
    "   - Accuracy: The proportion of correct predictions among the total number of cases examined.\n",
    "   - Precision: The ratio of correctly predicted positive observations to the total predicted positive observations.\n",
    "   - Recall: The ratio of correctly predicted positive observations to all observations in the actual class.\n",
    "\n",
    "#### <a id='toc1_6_5_2_'></a>[Why Is This Important?](#toc0_)\n",
    "\n",
    "1. **Training Configuration:**\n",
    "   - Compilation sets up the necessary components for training the model. Without this step, the model cannot be trained.\n",
    "\n",
    "2. **Optimization Strategy:**\n",
    "   - The choice of optimizer significantly affects how quickly and effectively the model learns. Adam is known for its ability to handle sparse gradients and noisy data.\n",
    "\n",
    "3. **Performance Evaluation:**\n",
    "   - The loss function guides the learning process. Categorical crossentropy is well-suited for multi-class problems, ensuring the model learns to distinguish between different boat types effectively.\n",
    "\n",
    "4. **Comprehensive Evaluation:**\n",
    "   - By including accuracy, precision, and recall, we get a more complete picture of the model's performance:\n",
    "     * Accuracy gives an overall view of correct predictions.\n",
    "     * Precision helps understand how many of the positive predictions are actually correct.\n",
    "     * Recall shows how many of the actual positive cases the model correctly identified.\n",
    "   - This is particularly important in scenarios where false positives or false negatives have different implications.\n",
    "\n",
    "5. **Model Interpretability:**\n",
    "   - These metrics help in understanding the model's strengths and weaknesses across different classes, which is crucial for improving the model or making decisions based on its predictions.\n",
    "\n",
    "6. **Alignment with Project Goals:**\n",
    "   - The choice of metrics should align with the specific goals of the project. For a boat classification task, knowing not just the accuracy but also the precision and recall can be crucial for understanding the model's reliability.\n",
    "\n",
    "7. **Debugging and Improvement:**\n",
    "   - Having multiple metrics helps in diagnosing issues during training. For example, high accuracy but low recall might indicate class imbalance issues.\n",
    "\n",
    "Section 2.5 is a critical step in preparing the model for training. It defines how the model will learn (optimizer and loss function) and how its performance will be evaluated (metrics). This configuration ensures that the training process is aligned with the specific requirements of the boat classification task and provides comprehensive insights into the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zIiK9qFpFnl8"
   },
   "source": [
    "### <a id='toc1_6_6_'></a>[2.6.\tTrain the model for 50 epochs and Early stopping while monitoring validation loss.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AeUMiSxIFnl9",
    "outputId": "45a8fc8e-64b1-41fe-a050-762921a25e87"
   },
   "outputs": [],
   "source": [
    "# Print the shape of labels in a batch\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "    print(\"Labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3cM5lGFFnl9",
    "outputId": "65be1a35-5a52-406a-80c0-a2cc803c6711"
   },
   "outputs": [],
   "source": [
    "# Check the shape of a batch from the training dataset\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"Shape of images in a batch:\", images.shape)\n",
    "    print(\"Shape of labels in a batch:\", labels.shape)\n",
    "\n",
    "# Print the model summary again\n",
    "model.summary()\n",
    "\n",
    "# Check the number of classes\n",
    "print(\"Number of classes:\", len(class_names))\n",
    "\n",
    "# Check if labels are one-hot encoded\n",
    "if len(labels.shape) == 2 and labels.shape[1] > 1:\n",
    "    print(\"Labels are one-hot encoded\")\n",
    "else:\n",
    "    print(\"Labels are not one-hot encoded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tW0xHaJUFnl9",
    "outputId": "0c31105a-100f-45c8-cb71-84cb66a48db8"
   },
   "outputs": [],
   "source": [
    "# 2.6: Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=50,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hqKTAGkuFnl9"
   },
   "source": [
    "#### <a id='toc1_6_6_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "- It's using the compiled model from Section 2.5\n",
    "- It's using the training and validation datasets prepared earlier.\n",
    "- We use EarlyStopping to prevent overfitting and stop training when validation loss stops improving.\n",
    "- The model is trained for up to 50 epochs, but may stop earlier due to early stopping.\n",
    "- Early stopping helps prevent overfitting by stopping training when validation performance starts to degrade.\n",
    "- `restore_best_weights=True` ensures we keep the model weights from the best epoch.\n",
    "\n",
    "#### <a id='toc1_6_6_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Training Progress:**\n",
    "   - The model trains for 17 epochs before early stopping kicks in.\n",
    "   - Training loss decreases from 1.1631 to 0.0331 over these epochs.\n",
    "   - Training accuracy improves from 64.25% to 99.14%.\n",
    "   - Training precision and recall also show significant improvements.\n",
    "\n",
    "2. **Validation Performance:**\n",
    "   - Validation accuracy improves from 80.62% in the first epoch to a peak of 89.38% in epochs 3.\n",
    "   - Validation loss doesn't consistently decrease, fluctuating between ~0.4 and ~0.9.\n",
    "   - Validation precision and recall generally improve but show some fluctuations.\n",
    "\n",
    "3. **Overfitting Indicators:**\n",
    "   - There's a growing gap between training and validation metrics as training progresses.\n",
    "   - By the final epoch, training accuracy is 99.14% while validation accuracy is 81.50%.\n",
    "\n",
    "5. **Metric Relationships:**\n",
    "   - Precision tends to be higher than recall, especially in the validation set.\n",
    "   - In later epochs, validation precision and recall start to diverge more.\n",
    "\n",
    "#### <a id='toc1_6_6_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. **Rapid Initial Learning:** The model learns quickly in the first few epochs, suggesting that the transfer learning approach (using MobileNetV2 as a base) is effective.\n",
    "\n",
    "2. **Overfitting:** There are clear signs of overfitting as training progresses. The model is learning the training data very well but isn't generalizing as effectively to the validation set.\n",
    "\n",
    "3. **Early Stopping Effectiveness:** The early stopping mechanism appears to be working, preventing further overfitting by stopping training at epoch 17.\n",
    "\n",
    "4. **Model Potential:** The model shows promise, achieving over 89% validation accuracy at its peak. However, the best performance isn't necessarily in the final epoch.\n",
    "\n",
    "5. **Class Imbalance or Difficulty:** The consistent gap between precision and recall in the validation set might indicate some classes are easier to identify than others, or there might be class imbalance issues.\n",
    "\n",
    "6. **Optimization Challenges:** The fluctuations in validation loss and metrics suggest that the model might be struggling to find an optimal set of parameters that generalize well.\n",
    "\n",
    "7. **Further Tuning Needed:** While the model shows good performance, there's room for improvement. Techniques like adjusting the learning rate, using more aggressive regularization, or fine-tuning the MobileNetV2 layers might help reduce overfitting and improve generalization.\n",
    "\n",
    "8. **Validation Strategy:** The fluctuations in validation metrics might also suggest that the validation set is relatively small or not fully representative. Considering k-fold cross-validation could provide more stable estimates of model performance.\n",
    "\n",
    "The model shows promising performance but exhibits signs of overfitting. The early stopping mechanism helps mitigate this, but further optimization could potentially improve the model's generalization capabilities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HV86ePrMFnl9"
   },
   "source": [
    "### <a id='toc1_5_7_'></a>[2.7.\tEvaluate the model on test images and print the test loss and accuracy.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2m4bBGXhFnl9",
    "outputId": "90613d4e-b223-4d3d-f3b2-c448e0feb147"
   },
   "outputs": [],
   "source": [
    "# 2.7: Evaluate the model\n",
    "test_loss, test_accuracy, test_precision, test_recall = model.evaluate(test_ds)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "print(f\"Test precision: {test_precision:.4f}\")\n",
    "print(f\"Test recall: {test_recall:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QpFjRNLPFnl9"
   },
   "source": [
    "#### <a id='toc1_6_7_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "- The code is using the method `model.evaluate()` to compute various metrics on this test set.\n",
    "- This section of code is evaluating the trained model on the test dataset.\n",
    "- The test dataset is a separate set of data that the model hasn't seen during training or validation.\n",
    "- It's used to provide an unbiased evaluation of the final model's performance.\n",
    "- This gives us an unbiased estimate of the model's performance on unseen data.\n",
    "\n",
    "#### <a id='toc1_6_7_2_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Test Loss:** 0.6169\n",
    "   - This is the average loss (error) of the model on the test set.\n",
    "   - It's calculated using the loss function specified during model compilation (likely categorical crossentropy).\n",
    "\n",
    "2. **Test Accuracy:** 0.8404 (84.04%)\n",
    "   - This indicates that the model correctly classified about 84.04% of the test samples.\n",
    "\n",
    "3. **Test Precision:** 0.8674 (86.74%)\n",
    "   - Precision is the ratio of correctly predicted positive observations to the total predicted positive observations.\n",
    "   - It suggests that when the model predicts a certain class, it's correct about 86.74% of the time.\n",
    "\n",
    "4. **Test Recall:** 0.8351 (83.51%)\n",
    "   - Recall is the ratio of correctly predicted positive observations to all actual positive observations.\n",
    "   - It indicates that the model correctly identifies 83.51% of the actual positive cases for each class.\n",
    "\n",
    "#### <a id='toc1_6_7_3_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. **Good Overall Performance:**\n",
    "   - An accuracy of 84.04% on the test set indicates that the model performs well on unseen data. This is a strong result for a multi-class image classification task.\n",
    "\n",
    "2. **Balanced Precision and Recall:**\n",
    "   - The relatively close values of precision (86.74%) and recall (83.51%) suggest that the model has a good balance between making correct positive predictions and capturing all positive instances.\n",
    "\n",
    "3. **Generalization:**\n",
    "   - The model's performance on the test set is similar to its best performance on the validation set (which peaked around 89% accuracy). This suggests good generalization - the model has learned patterns that apply well to new, unseen data.\n",
    "\n",
    "4. **Potential for Real-World Application:**\n",
    "   - With 84% accuracy on unseen data, this model could be viable for many real-world applications in boat classification, depending on the specific requirements of the task.\n",
    "\n",
    "5. **Room for Improvement:**\n",
    "   - While the performance is good, there's still room for improvement. About 16% of test samples are still misclassified.\n",
    "\n",
    "6. **Consistent Performance Across Metrics:**\n",
    "   - The high and relatively close values for accuracy, precision, and recall indicate that the model performs consistently well across different evaluation criteria.\n",
    "\n",
    "7. **Class Balance Consideration:**\n",
    "   - The slight difference between precision and recall might indicate some minor imbalance in how the model performs across different classes. Some classes might be slightly easier for the model to identify than others.\n",
    "\n",
    "8. **Validation of Training Process:**\n",
    "   - These results validate the effectiveness of the transfer learning approach and the training process used. The model has successfully learned to generalize from the training data to new, unseen examples.\n",
    "\n",
    "**Section 2.7** demonstrates that the trained model performs well on unseen data, with strong and balanced metrics across accuracy, precision, and recall. This suggests that the model has successfully learned to classify boat images and can generalize this knowledge to new examples. While there's always room for improvement, these results indicate a successful implementation of the image classification task.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kl_4xx49Fnl9"
   },
   "source": [
    "### <a id='toc1_5_8_'></a>[2.8.\tPlot Train loss Vs Validation loss and Train accuracy Vs Validation accuracy.](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TslYfYi_Fnl9",
    "outputId": "45bc0498-1652-4bab-bfc7-2f118c15100c"
   },
   "outputs": [],
   "source": [
    "# 2.8: Plot training history\n",
    "def plot_training_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "    ax1.plot(history.history['loss'], label='Train')\n",
    "    ax1.plot(history.history['val_loss'], label='Validation')\n",
    "    ax1.set_title('Model Loss')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.legend()\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='Train')\n",
    "    ax2.plot(history.history['val_accuracy'], label='Validation')\n",
    "    ax2.set_title('Model Accuracy')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_training_history(history)\n",
    "\n",
    "print(\"Final Training Loss:\", history.history['loss'][-1])\n",
    "print(\"Final Validation Loss:\", history.history['val_loss'][-1])\n",
    "print(\"Final Training Accuracy:\", history.history['accuracy'][-1])\n",
    "print(\"Final Validation Accuracy:\", history.history['val_accuracy'][-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "myVSNvQlFnl9"
   },
   "source": [
    "#### <a id='toc1_6_8_1_'></a>[Explanations](#toc0_)\n",
    "\n",
    "**Section 2.8** is plotting the training history of the model, showing how loss and accuracy changed over epochs for both training and validation sets. It also provides the final values for training and validation loss and accuracy.\n",
    "\n",
    "#### <a id='toc1_6_8_1_'></a>[Observations](#toc0_)\n",
    "\n",
    "1. **Loss Curves:**\n",
    "   - Training loss decreases rapidly and continues to decline steadily.\n",
    "   - Validation loss initially decreases but then becomes volatile and increases towards the end.\n",
    "\n",
    "2. **Accuracy Curves:**\n",
    "   - Training accuracy increases rapidly and plateaus near 100%.\n",
    "   - Validation accuracy improves quickly initially, then fluctuates between about 82% and 89%.\n",
    "\n",
    "3. **Final Metrics:**\n",
    "   - Final Training Loss: 0.0331 (very low)\n",
    "   - Final Validation Loss: 0.8803 (much higher than training loss)\n",
    "   - Final Training Accuracy: 99.14% (extremely high)\n",
    "   - Final Validation Accuracy: 82.50% (good, but much lower than training)\n",
    "\n",
    "#### <a id='toc1_6_8_1_'></a>[Conclusions](#toc0_)\n",
    "\n",
    "1. **Overfitting:**\n",
    "   - The large gap between training and validation metrics (both loss and accuracy) clearly indicates overfitting.\n",
    "   - The model has learned to perform extremely well on the training data but doesn't generalize as well to new data.\n",
    "\n",
    "2. **Early Stages of Training:**\n",
    "   - The model learns quickly in the first few epochs, showing the effectiveness of transfer learning using MobileNetV2.\n",
    "\n",
    "3. **Validation Instability:**\n",
    "   - The fluctuations in validation accuracy and increasing validation loss suggest the model struggles to find a consistent set of parameters that generalize well.\n",
    "\n",
    "4. **Potential Early Stopping Point:**\n",
    "   - The best validation performance appears to be around epochs 6-8. Stopping training earlier might have yielded a model that generalizes better.\n",
    "\n",
    "5. **Model Capacity:**\n",
    "   - The model's ability to achieve near-perfect training accuracy suggests it has more than enough capacity to learn the training data.\n",
    "\n",
    "6. **Regularization Needs:**\n",
    "   - The significant overfitting suggests that stronger regularization techniques (e.g., dropout, L2 regularization) might be beneficial.\n",
    "\n",
    "7. **Learning Rate Considerations:**\n",
    "   - The smooth decrease in training loss suggests the learning rate might be appropriate, but a learning rate schedule or decay might help in later epochs.\n",
    "\n",
    "8. **Validation Set Size:**\n",
    "   - The volatility in validation metrics might indicate a relatively small validation set. A larger validation set could provide more stable estimates.\n",
    "\n",
    "9. **Real-World Performance Expectations:**\n",
    "   - Despite overfitting, the model still achieves over 80% accuracy on validation data, which could be useful in many real-world applications, depending on the specific requirements.\n",
    "\n",
    "10. **Further Optimization Potential:**\n",
    "    - There's clear room for improvement in the model's ability to generalize. Techniques like data augmentation, fine-tuning of the base model, or ensemble methods could potentially help.\n",
    "\n",
    "**Section 2.8** reveals a model that performs exceptionally well on training data but shows clear signs of overfitting. While the validation performance is still good, there's significant potential for improvement in the model's ability to generalize to new, unseen data. This analysis provides valuable insights for further refinement of the model and training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twtsj9AVFnl9"
   },
   "source": [
    "#### <a id='toc1_7_'></a>[3.\tCompare the results of both models built in steps 1 and 2 and state your observations.](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7pZXpd0Fnl9"
   },
   "source": [
    "Comparison of Models from Section 1 and Section 2\n",
    "\n",
    "1. **Model Architecture:**\n",
    "   - Section 1: Custom CNN built from scratch\n",
    "   - Section 2: Lightweight model using transfer learning with MobileNetV2 as the base\n",
    "\n",
    "2. **Final Test Performance:**\n",
    "   - *Section 1 (Custom CNN):*\n",
    "     * **Test accuracy:** 33.65%\n",
    "     * **Test loss:** 1.7490\n",
    "     * **Test precision:** 42.86%\n",
    "     * **Test recall:** 11.54%\n",
    "\n",
    "   - *Section 2 (MobileNetV2 Transfer Learning):*\n",
    "     * **Test accuracy:** 84.04%\n",
    "     * **Test loss:** 0.6169\n",
    "     * **Test precision:** 86.74%\n",
    "     * **Test recall:** 83.51%\n",
    "\n",
    "3. **Training Behavior:**\n",
    "   - *Section 1 (Custom CNN):*\n",
    "     * Training accuracy increased from 32.80% (Epoch 1) to 42.80% (Epoch 20).\n",
    "     * Validation accuracy fluctuated but generally improved from 31.25% (Epoch 1) to 37.50% (Epoch 20).\n",
    "     * Both training and validation loss decreased steadily\n",
    "\n",
    "   - *Section 2 (MobileNetV2 Transfer Learning):*\n",
    "     * Training accuracy increased from about 64.25% to 99.14% over 17 epochs\n",
    "     * Training loss decreased steadily, while validation loss was more volatile\n",
    "\n",
    "4. **Model Complexity and Size:**\n",
    "   - *Section 1 (Custom CNN):* Likely simpler and smaller, but exact parameters not provided\n",
    "   - *Section 2 (MobileNetV2 Transfer Learning):* Based on MobileNetV2, designed to be lightweight for mobile deployment\n",
    "\n",
    "**Observations:**\n",
    "\n",
    "1. **Performance Improvement:**\n",
    "   - The *MobileNetV2-based model* significantly outperformed the *custom CNN* in terms of **test accuracy** (*84.04% vs 33.65%*).\n",
    "   - This demonstrates the power of transfer learning, leveraging pre-trained weights on a large dataset.\n",
    "\n",
    "1. **Training Stability:**\n",
    "   - The *custom CNN* showed more stable training, with gradual improvements in both training and validation metrics.\n",
    "   - The *MobileNetV2-based model* had more erratic validation performance, particularly in accuracy, which could indicate issues with the validation set or overfitting.\n",
    "\n",
    "2. **Mobile Deployment Potential:**\n",
    "   - The *MobileNetV2-based model* is specifically designed for mobile deployment, making it more suitable for this purpose.\n",
    "   - Its significantly better performance also makes it a more viable candidate for real-world application.\n",
    "\n",
    "3. **Learning Efficiency:**\n",
    "   - The *MobileNetV2-based model* achieved better performance in the same number of epochs, likely due to the advantage of pre-trained weights.\n",
    "\n",
    "4. **Overfitting Concerns:**\n",
    "   - Both models show signs of overfitting, but it's more pronounced in the *MobileNetV2 model*, particularly in the later epochs.\n",
    "\n",
    "5. **Room for Improvement:**\n",
    "   - Both models, especially the *custom CNN*, have significant room for improvement given the relatively low accuracies.\n",
    "\n",
    "**Conclusions:**\n",
    "\n",
    "1. The transfer learning approach with MobileNetV2 (Section 2) is superior in terms of performance and suitability for mobile deployment.\n",
    "2. However, both models could benefit from further optimization, potentially including:\n",
    "   - More extensive data augmentation\n",
    "   - Addressing class imbalance issues\n",
    "   - Fine-tuning hyperparameters\n",
    "   - Potentially increasing model complexity for the custom CNN or unfreezing more layers in the MobileNetV2 model\n",
    "3. The unusual behavior in the MobileNetV2 model's validation accuracy warrants further investigation into the validation set and training process.\n",
    "4. For practical deployment, the MobileNetV2 model is the better choice, but efforts should be made to improve its recall without significantly sacrificing precision.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "include_colab_link": true,
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
