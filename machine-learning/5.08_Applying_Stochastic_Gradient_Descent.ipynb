{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "13eTBM6loSDX"
   },
   "source": [
    "## __Applying Stochastic Gradient Descent__\n",
    "\n",
    "Let's look at how to construct a stochastic gradient descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IswXUOpYe6DX"
   },
   "source": [
    "## Step 1: Import Required Libraries and Load the Dataset\n",
    "\n",
    "- Import NumPy, pandas, matplotlib.pyplot, Seaborn, and sklearn libraries\n",
    "- Load the breast cancer dataset from sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "tz-Q-cgCek7Y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4G4Jo_1ffAL8"
   },
   "source": [
    "## Step 2: Create Training and Test Split\n",
    "\n",
    "- Split the dataset into training and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XyrkcWszek7a"
   },
   "outputs": [],
   "source": [
    "bc = datasets.load_breast_cancer()\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "SnwRJVdkek7a"
   },
   "outputs": [],
   "source": [
    "n_iterations = 100\n",
    "learning_rate = 0.01\n",
    " \n",
    "def predict(X, y, coef):\n",
    "    '''\n",
    "    Activation function: w0 + w1*x1 + w2*x2 + ... + wn*xn\n",
    "    '''\n",
    "    output = np.dot(X, coef[1:]) + coef[0]\n",
    "    '''\n",
    "    Unit Step function: Predict 1 if output >= 0 else 0\n",
    "    '''\n",
    "    return np.where(output >= 0.0, 1, 0)\n",
    "     \n",
    "def fit(X, y):\n",
    "        rgen = np.random.RandomState(1)\n",
    "        coef_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        for _ in range(n_iterations):\n",
    "            for xi, expected_value in zip(X, y):\n",
    "                predicted_value = predict(xi, target, coef_)\n",
    "        \n",
    "                coef_[1:] += learning_rate * (expected_value - predicted_value) * xi\n",
    "                coef_[0] += learning_rate * (expected_value - predicted_value) * 1\n",
    "        return coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uu5ixUonfHlh"
   },
   "source": [
    "## Step 3: Define the CustomPerceptron Class and Its Methods\n",
    "\n",
    "- Define `predict`, `fit`, `activation`, and `score` methods for the CustomPerceptron class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "0rGaopJoek7b"
   },
   "outputs": [],
   "source": [
    "class CustomPerceptron(object):\n",
    "     \n",
    "    def __init__(self, n_iterations=100, random_state=1, learning_rate=0.01):\n",
    "        self.n_iterations = n_iterations\n",
    "        self.random_state = random_state\n",
    "        self.learning_rate = learning_rate\n",
    " \n",
    "    '''\n",
    "    Stochastic Gradient Descent\n",
    "     \n",
    "    1. Weights are updated based on each training examples.\n",
    "    2. Learning of weights can continue for multiple iterations.\n",
    "    3. Learning rate needs to be defined.\n",
    "    '''\n",
    "    def fit(self, X, y):\n",
    "        rgen = np.random.RandomState(self.random_state)\n",
    "        self.coef_ = rgen.normal(loc=0.0, scale=0.01, size=1 + X.shape[1])\n",
    "        for _ in range(self.n_iterations):\n",
    "            for xi, expected_value in zip(X, y):\n",
    "                predicted_value = self.predict(xi)\n",
    "                self.coef_[1:] += self.learning_rate * (expected_value - predicted_value) * xi\n",
    "                self.coef_[0] += self.learning_rate * (expected_value - predicted_value) * 1\n",
    "     \n",
    "    '''\n",
    "    Activation function calculates the value of weighted sum of input value\n",
    "    '''\n",
    "    def activation(self, X):\n",
    "            return np.dot(X, self.coef_[1:]) + self.coef_[0]\n",
    "     \n",
    "    '''\n",
    "    Prediction is made on the basis of unit step function.\n",
    "    '''\n",
    "    def predict(self, X):\n",
    "        output = self.activation(X)\n",
    "        return np.where(output >= 0.0, 1, 0)\n",
    "     \n",
    "    '''\n",
    "    Model score is calculated based on comparison of\n",
    "    expected value and predicted value.\n",
    "    '''\n",
    "    def score(self, X, y):\n",
    "        misclassified_data_count = 0\n",
    "        for xi, target in zip(X, y):\n",
    "            output = self.predict(xi)\n",
    "            if(target != output):\n",
    "                misclassified_data_count += 1\n",
    "        total_data_count = len(X)\n",
    "        self.score_ = (total_data_count - misclassified_data_count)/total_data_count\n",
    "        return self.score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eE5v2FrLfWd3"
   },
   "source": [
    "## Step 4: Create and Evaluate the CustomPerceptron Model\n",
    "\n",
    "- Instantiate the CustomPerceptron class\n",
    "- Fit the model to the training data\n",
    "- Evaluate the model's performance on the test and training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1607,
     "status": "ok",
     "timestamp": 1683127508806,
     "user": {
      "displayName": "Sreelakshmi C V",
      "userId": "04477517605899898333"
     },
     "user_tz": -330
    },
    "id": "zKbsEU6Fek7c",
    "outputId": "822b081c-5d8b-4254-acd2-1b315ee852d5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9064327485380117, 0.9296482412060302)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prcptrn = CustomPerceptron()\n",
    "\n",
    "prcptrn.fit(X_train, y_train)\n",
    "\n",
    "prcptrn.score(X_test, y_test), prcptrn.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cYl_ezEmxOrB"
   },
   "source": [
    "__Observation__\n",
    "- The results of the first one are displayed as 0.9064327485380117 for the output for the test and 0.9296482412060302 for the output for the train."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
