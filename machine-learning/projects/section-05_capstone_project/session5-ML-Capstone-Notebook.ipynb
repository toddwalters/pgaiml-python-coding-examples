{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Florida Bike Rentals Prediction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "## **Context**\n",
    "-----------------------------\n",
    "\n",
    "Aura customer FloridaBikeRentals.com is unable to predict peaks and troughs in demand for their high-end bikes. \n",
    "\n",
    "-----------------------------\n",
    "## **Objectives**\n",
    "-----------------------------\n",
    "\n",
    "They have approached Aura to customize a marketing tool to predict bike-sharing demand. To stabilize the demand, devise marketing strategies using the bike-sharing dataset.  Based on rented bike count, the hour of the day, the day's temperature, humidity, wind speed, rainfall, holidays, and many other factors, build a model to predict the bike count required at each hour for the stable supply of rental bikes. \n",
    "\n",
    "-----------------------------\n",
    "## **Dataset**\n",
    "-----------------------------\n",
    "\n",
    "- **Date :** Date in year-month-day format\n",
    "\n",
    "- **Rented Bike Count :** Count of bikes rented at each hour\n",
    "\n",
    "- **Hour :** Hour of the day \n",
    "\n",
    "- **Temperature :** Temperature in Celsius\n",
    "\n",
    "- **Humidity :** Humidity in percentage \n",
    "\n",
    "- **Snowfall :** Snowfall in cm\n",
    "\n",
    "- **Holiday :** Is it a holiday? Holiday/ No holiday\n",
    "\n",
    "- **Windspeed :** Speed of the wind in meters per sec (m/s)\n",
    "\n",
    "- **Visibility :** Visibility in meters\n",
    "\n",
    "- **Dew Point Temperature :** Dew point temperature in Celcius\n",
    "\n",
    "- **Solar Radiation :** Radiant energy from the sun measured in MJ/m2 (per meters squared)\n",
    "\n",
    "- **Rainfall :** Rainfall in mm\n",
    "\n",
    "- **Seasons :** Season of the year â€“ Winter, Summer, Spring, and Autumn\n",
    "\n",
    "- **Functional Day :** Bike rented during functional (Fun) and nonfunctional hours (NoFunc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Importing the libraries and overview of the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for data manipulation\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Importing libraries for data visualization\n",
    "import seaborn as sns\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Importing libraries for building linear regression model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Importing libraries for scaling the data\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# To ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Load the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading both train and test datasets\n",
    "\n",
    "rental_df = pd.read_csv('FloridaBikeRentals.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the first 5 rows of the dataset\n",
    "rental_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations:**\n",
    "- No observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Checking the info of the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations:**\n",
    "\n",
    "- The train dataset has **8760 observations and 14 columns**.\n",
    "- We observe that some of the columns have data type **object**, which means they are strings or categorical variables.\n",
    "- The remaining variables are all numerical in nature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **2. Check for null values in any columns and handle the missing values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking missing values\n",
    "plt.figure(figsize=(14,5))\n",
    "sns.heatmap(rental_df.isnull(), cbar=True, yticklabels=False)\n",
    "plt.xlabel(\"Column Name\", size=14, weight='bold')\n",
    "plt.title(\"Places of Missing Values in the Dataset\", size=17, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations**\n",
    " - There are no missing values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **3. Convert Date Columns to Date Format and extract day, month, and weekdays/weekend from date column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_df['Date'] = pd.to_datetime(rental_df['Date'], format=\"%d/%m/%Y\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting day, month, day of week and weekdays/weekend from Date column\n",
    "\n",
    "rental_df['Date'] = pd.to_datetime(rental_df['Date'])\n",
    "rental_df['Month'] = rental_df['Date'].apply(lambda x: x.month)\n",
    "rental_df['Day_of_Week'] = rental_df['Date'].dt.day_name()\n",
    "rental_df['Weekdays_Weekend'] = rental_df['Day_of_Week'].apply(lambda x : 1 if x=='Saturday' or x=='Sunday' else 0)\n",
    "rental_df = rental_df.drop(['Date', 'Day_of_Week'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rental_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **4. Check correlation of features using a heatmap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new df with only numerical columns\n",
    "rental_df_numerical = rental_df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Checking the correlation of numerical columns\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(rental_df_numerical.corr(), annot=True, cmap='PiYG')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations**\n",
    "- The correlation heatmap shows the range of correlation between each of the variables/features.  The more darker the color the more they are correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **5. Plot The Distribution Plot of Rented Bike Count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing Distribution\n",
    "\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.distplot(rental_df['Rented Bike Count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations**\n",
    "- The distribution plot shows that the density of the Rented Bike Count is at the peak around 350."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **6. Plot the histogram of all numerical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric Features Information\n",
    "\n",
    "rental_df_numerical.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the numeric features\n",
    "\n",
    "rental_df_numerical.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in rental_df_numerical[:]:\n",
    "    sns.histplot(rental_df[col])\n",
    "    plt.axvline(rental_df[col].mean(), color='magenta', linestyle='dashed', linewidth=2)\n",
    "    plt.axvline(rental_df[col].median(), color='cyan', linestyle='dashed', linewidth=2)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations**\n",
    "- The histogram plots shows the distribution of each of the numerical variables across their bins\n",
    "- Each graph shows when their count reach its peak. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **7. Plot the box plot of Rented Bike Count against all the categorical features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting categorical features\n",
    "\n",
    "categorical_features = rental_df.select_dtypes(include=['object'])\n",
    "\n",
    "categorical_features.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Box Plot to visualize and trying to get information from plot\n",
    "\n",
    "for col in categorical_features:\n",
    "    plt.figure(figsize=(10,8))\n",
    "    sns.boxplot(x=col, y='Rented Bike Count', data=rental_df, palette='Set1')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations**\n",
    "- Less demand in Winter Seasons\n",
    "- Slightly Higher demand during Non-Holidays\n",
    "- Almost no demand on Non-Functioning Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Counts of Functioning Day\n",
    "\n",
    "rental_df['Functioning Day'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Cat Plot for more information\n",
    "\n",
    "sns.catplot(x='Seasons', y='Rented Bike Count', data=rental_df, palette='Set1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations**\n",
    "- We can clearly see that there is less demand for rented bikes in the Winter Season"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Plot the Seaborn Catplot fo Rented Bike Count against features like Hour, Holiday, Rainfall(mm), Snowfall(cm), Weekdays_Weekend and give your inferences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Cat Plot on some features to get more information\n",
    "\n",
    "feature_list=['Hour', 'Holiday', 'Rainfall(mm)', 'Snowfall (cm)', 'Weekdays_Weekend']\n",
    "\n",
    "for feature in feature_list:\n",
    "    plt.figure(figsize=(10,18), dpi=300)\n",
    "    sns.catplot(x=feature, y='Rented Bike Count', data=rental_df, palette='Set3')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Observations**\n",
    "\n",
    "_From Hour vs Rented Bikes_\n",
    "- We can clearly see there is high demand for Rented Bikes between the Office Hours\n",
    "\n",
    "_From Weekday-Weekends vs Rented Bikes_\n",
    "- Weekdays has a comparatively high demand for rented bikes as compared to Weekend days\n",
    "\n",
    "_From Rainfall vs Rented Bikes_\n",
    "- We can see as rainfall increases demand for Rented Bikes decreases\n",
    "\n",
    "_From Snowfall vs Rented Bikes_\n",
    "- WE can see that as snowfall increases demand for Rented Bikes decreases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **9. Encode The Categorical Features Into Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dummy variables for categorical features\n",
    "\n",
    "dummy_categorical_features = pd.get_dummies(categorical_features, drop_first=True)\n",
    "\n",
    "dummy_categorical_features.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating the numeric columns and dummy columns and created final data frame\n",
    "\n",
    "final_df = pd.concat([dummy_categorical_features, rental_df_numerical], axis=1)\n",
    "\n",
    "# Showing the first 5 rows of the final data frame\n",
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describing the final data frame\n",
    "final_df.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **10. Identify the target variable and split the dataset into train and test with a ratio of 80:20 and random state of 12**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Splitting the data\n",
    "\n",
    "X = final_df.drop('Rented Bike Count', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=final_df['Rented Bike Count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Splitting\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **11. Perform Standard Scaling of the training dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_test = std.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **12. Perform Linear Regression, Lasso Regression and Ridge Regression for predicting the bike count required at each hour and compare the results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of matrix to store the evaluation matrix of all models\n",
    "\n",
    "mse_list = []\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "adj_r2_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating functions to run different models\n",
    "\n",
    "# def run_model(model, X_train, X_test, y_train, y_test):\n",
    "#     model.fit(X_train, y_train)\n",
    "#     y_pred = model.predict(X_test)\n",
    "#     mse = mean_squared_error(y_test, y_pred)\n",
    "#     rmse = np.sqrt(mse)\n",
    "#     r2 = r2_score(y_test, y_pred)\n",
    "#     adj_r2 = 1 - (1-r2)*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
    "#     mean_squared_error.append(mse)\n",
    "#     root_mean_squared_error.append(rmse)\n",
    "#     r2_list.append(r2)\n",
    "#     adj_r2_list.append(adj_r2)\n",
    "#     print(\"Mean Squared Error: \", mse)\n",
    "#     print(\"Root Mean Squared Error: \", rmse)\n",
    "#     print(\"R2 Score: \", r2)\n",
    "#     print(\"Adjusted R2 Score: \", adj_r2)\n",
    "\n",
    "mse_list = []\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "adj_r2_list = []\n",
    "\n",
    "def run_model(model, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    # Fit Model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get Metrics\n",
    "    preds = model.predict(X_test)\n",
    "    \n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    print('\\n==========================Evaluation Matrix==========================')\n",
    "    MSE = mean_squared_error(y_test, preds)\n",
    "    print(\"MSE :\" , MSE)\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    print(\"RMSE :\" , RMSE)\n",
    "    r2 = r2_score(y_test, preds)\n",
    "    print(\"R2 :\" , r2)\n",
    "    adj_r2 = 1 - (1-r2_score(y_test, preds))*((X_test.shape[0] - 1)/(X_test.shape[0] - X_test.shape[1] - 1))\n",
    "    print(\"Adjusted R2 :\" , adj_r2)\n",
    "    \n",
    "    train_class_preds = linear_model.predict(X_train)\n",
    "    print('\\n==========================Evaluation Matrix==========================')\n",
    "    \n",
    "    mse_list.append(MSE)\n",
    "    rmse_list.append(RMSE)\n",
    "    r2_list.append(r2)\n",
    "    adj_r2_list.append(adj_r2)\n",
    "    \n",
    "    # Plotting the graph\n",
    "    print('\\n================================================================Evaluation Graph================================================================\\n')\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(np.array(y_test[:100]))\n",
    "    plt.plot(preds[:100])\n",
    "    plt.legend(['ACTUAL','PREDICTED'], prop={'size': 20})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Linear Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression Model\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "linear_model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "\n",
    "run_model(linear_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Observations**\n",
    "- The above plot shows how far the predicted values are away from actual values in case of Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Lasso Regression Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Finding the best parameters for Lasso by GridSearchCV\n",
    "lasso_model = Lasso()\n",
    "\n",
    "parameters = {'alpha': [1e-15, 1e-13, 1e-10, 1e-8, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1, 1, 5, 10, 20, 30, 40, 45, 50, 55, 60, 100, 0.0014]}\n",
    "lasso_grid = GridSearchCV(lasso_model, parameters, scoring='neg_mean_squared_error', cv=5)\n",
    "lasso_grid.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \", lasso_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "# Creating Lasso Model with best parameters\n",
    "lasso_model = Lasso(alpha=0.1)\n",
    "\n",
    "# Calling train_linear_model function to train, fit and evaluation of the Lasso Model\n",
    "run_model(lasso_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Observations**\n",
    "- The above plot shows how far the predicted values are away from actual values in case of Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Ridge Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Finding the best parameters for Ridge by GridSearchCV\n",
    "ridge_model = Ridge()\n",
    "\n",
    "parameters = {'alpha': [1e-15, 1e-10, 1e-8, 1e-5, 1e-4, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 60, 100, 0.5, 1.5, 1.6, 1.7, 1.8, 1.9]}\n",
    "ridge_grid = GridSearchCV(ridge_model, parameters, scoring='neg_mean_squared_error', cv=3)\n",
    "ridge_grid.fit(X_train, y_train)\n",
    "print(\"Best Parameters: \", ridge_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge = Ridge(alpha=5)\n",
    "\n",
    "run_model(ridge_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Obervation**\n",
    "- The above plot shows how far the predicted values are away from actual values in the case of Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Combined Evaluation Matrix of All Models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating dictionary to store all the matrices\n",
    "all_model_matrices={'Mean_square_error':mse_list, 'Root_Mean_square_error':rmse_list, 'R2':r2_list, 'Adjusted_R2':adj_r2_list}\n",
    "\n",
    "# List of all models created\n",
    "model_name=['Linear','Lasso','Ridge']\n",
    "\n",
    "# Converting dictionary to dataframe for easy visual\n",
    "matrices_df=pd.DataFrame.from_dict(all_model_matrices,orient=\"index\",columns=model_name)\n",
    "\n",
    "matrices_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transposing matrices_df for easy and clear view and saving that as new final matrices df\n",
    "final_matrices=matrices_df.transpose().reset_index().rename(columns={'index':'Model'})\n",
    "\n",
    "final_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Bar Plot to Visualize the Adjusted R2 of Each Model\n",
    "plt.figure(figsize=(14,4), dpi=300)\n",
    "sns.barplot(x='Model', y='Adjusted_R2', data=final_matrices.sort_values('Adjusted_R2'), palette='flare').set(title='Adjusted R2 of Each Model')\n",
    "plt.xticks(rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Observations**\n",
    "1. On Holiday and Non-Working Days there is demand in rented bikes.\n",
    "2. There is a surge of high demand in the morning at 8AM and in the evening at 6PM, this demand is potentially driven by people needing to rent bikes to go to work at 8AM in the morning and retuning from work at 6PM in the evening.\n",
    "3. People preferred more rented bikes in the Morning rather than in the Evening.\n",
    "4. When the rainfall was less, people have booked more bikes, with a few exceptions.\n",
    "5. The Temperature, Hour and Humidity are the most important features that positively drive the total rented bikes count.\n",
    "6. After performing the various models the Lasso and Ridge models were found to be slightly better models that can be used for the Bike Sharing Demand Prediction since the performance metrics (mse, rmse) shows lower and (r2, adjusted_r2_ shows a higher values for the Lasso and Ridge models.\n",
    "7. We can use either Lasso or Ridge model for the bike rental stations.\n",
    "8. For further improvement int he performance, one would need to try out more complex models like RandomForest Regressor, GradientBoosting Regressor, LightGBM regressor, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
