{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VTllDLbHx_TD"
   },
   "source": [
    "#Accuracy Matrices in Machine Learning\n",
    "In this section, let us understand how to measure the accuracy of collaborative filtering.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boHN7J0p97-s"
   },
   "source": [
    "## Step 1: Import Required Libraries and Check How It Is Evaluated\n",
    "\n",
    "- Import package pandas \n",
    "- Import package surprise\n",
    "- Import package collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63458,
     "status": "ok",
     "timestamp": 1683516290445,
     "user": {
      "displayName": "Sreelakshmi C V",
      "userId": "04477517605899898333"
     },
     "user_tz": -330
    },
    "id": "R0d3kX6h8_kn",
    "outputId": "4c926d8e-435c-4069-c788-391e8e81d195"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "!pip install scikit-surprise\n",
    "# !conda install -y -c conda-forge scikit-surprise # If you use conda on a non-Colab environment\n",
    "from surprise import SVD\n",
    "from surprise import KNNBaseline\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import LeaveOneOut\n",
    "from surprise import Reader\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vSTKIAA-9-jd"
   },
   "source": [
    "## Step 2: Load and Merge the Datasets\n",
    "\n",
    "- Read two datasets: movies and ratings\n",
    "- Merge the datasets and check the head of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1683516493560,
     "user": {
      "displayName": "Sreelakshmi C V",
      "userId": "04477517605899898333"
     },
     "user_tz": -330
    },
    "id": "lrDsOFqj8_kp",
    "outputId": "6ab4ffe7-eed1-4624-e976-040993a8fbb8"
   },
   "outputs": [],
   "source": [
    "movies = pd.read_csv('movies.csv')\n",
    "ratings = pd.read_csv('ratings.csv')\n",
    "df = pd.merge(movies, ratings, on ='movieId', how='inner')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoEAZUudPH_I"
   },
   "source": [
    "__Observation:__\n",
    "- Here, we can see the head of the merged dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8NRi3ZbU-Avu"
   },
   "source": [
    "## Step 3: Prepare the Data for the Model\n",
    "\n",
    "- Create a Reader object with a rating scale from 0.5 to 5\n",
    "- Load the data into a dataset object\n",
    "- Split the data into train and test sets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7AnF2NzE8_kp"
   },
   "outputs": [],
   "source": [
    "reader = Reader(rating_scale=(0.5, 5))\n",
    "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=0.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1yShZh3-Cts"
   },
   "source": [
    "## Step 4: Use SVD Algorithm, Train on the Train Set, and Predict on the Test Set\n",
    "\n",
    "- Now let's build a model of singular value decomposition with a random state.\n",
    "- Fit the model with the train set\n",
    "- Make predictions with the test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bJbfyABr8_kp"
   },
   "outputs": [],
   "source": [
    "algo = SVD(random_state=0)\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-n0i6X4HdRla"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bs5P-xo2-GMk"
   },
   "source": [
    "## Step 5: Calculate RMSE and MAE\n",
    "\n",
    "- Define a function to check the MAE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S_X1Iz_28_kp"
   },
   "outputs": [],
   "source": [
    "def MAE(predictions):\n",
    "    return accuracy.mae(predictions, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IMGcHsSO8_kq"
   },
   "outputs": [],
   "source": [
    "def RSME(predictions):\n",
    "    return accuracy.rmse(predictions, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1683516746897,
     "user": {
      "displayName": "Sreelakshmi C V",
      "userId": "04477517605899898333"
     },
     "user_tz": -330
    },
    "id": "YLcHRfn-8_kq",
    "outputId": "fb06bad0-0ad5-4f14-fae7-3b291053e0c1"
   },
   "outputs": [],
   "source": [
    "print(\"RMSE: \", RSME(predictions))\n",
    "print(\"MAE :\", MAE(predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cSIA21_ahBvU"
   },
   "source": [
    "__Observations:__\n",
    "- The RMSE score is 0.89 and the MAE is 0.68.\n",
    "- This is one method of evaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5-wwvs79-H6m"
   },
   "source": [
    "## Step 6: Define GetTopN Function\n",
    "\n",
    "- There is also another method for TopN evaluation, and N may be any value.\n",
    "- Let's consider n = 10 and a minimum rating = 4.0.\n",
    "\n",
    "*   To create an empty dictionary of TopN, let’s append the movie ID, estimated rating, and their respective user ID.\n",
    "*    For topN items, we will sort the rating and return the topN.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NZXogvgK8_kq"
   },
   "outputs": [],
   "source": [
    "def GetTopN(predictions, n=10, minimumRating=4.0):\n",
    "    topN = defaultdict(list)\n",
    "    for userid, movieid, actualRating, estimatedRating, _ in predictions:\n",
    "        if (estimatedRating >= minimumRating):\n",
    "            topN[int(userid)].append((int(movieid), estimatedRating))\n",
    "            \n",
    "    for userid, ratings in topN.items():\n",
    "        ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "        topN[int(userid)] = ratings[:n]\n",
    "        \n",
    "    return topN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03wIWQg_-K5L"
   },
   "source": [
    "## Step 7: Perform Leave-One-Out Cross Validation\n",
    "\n",
    "- To get topN, let’s use Leave-One-Out Cross Validation (LOOCV).\n",
    "-  Apply LOOCV to the train set and test set, fit the algo model to the train set, and predict using the test set\n",
    "- Based on the prediction, we will have the topN for the 10 values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tCMbZgp58_kr"
   },
   "outputs": [],
   "source": [
    "LOOCV = LeaveOneOut(n_splits=1, random_state=1)\n",
    "\n",
    "for trainset, testset in LOOCV.split(data):\n",
    "    algo.fit(trainset)\n",
    "    leftoutpredictions = algo.test(testset)\n",
    "    bigTestset = trainset.build_anti_testset()\n",
    "    allpredictions = algo.test(bigTestset)\n",
    "    topNpredicted = GetTopN(allpredictions, n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1101,
     "status": "ok",
     "timestamp": 1683517179919,
     "user": {
      "displayName": "Sreelakshmi C V",
      "userId": "04477517605899898333"
     },
     "user_tz": -330
    },
    "id": "j7UeLtuAlWQn",
    "outputId": "76667295-febc-4009-8c7b-30f55b650025",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "topNpredicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WdZYrrcc5ES"
   },
   "source": [
    "__Observation:__\n",
    "- Here, we have the top 10 values for each userid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m4STX7MT-b3H"
   },
   "source": [
    "## Step 8: Calculate HitRate\n",
    "\n",
    "- The HitRate function can be defined as the number of hits divided by the number of test users, representing the system's overall hit rate. A higher value indicates that we can propose a rating removal more frequently.\n",
    "- Calculate the HitRate with the top N predicted ratings and the left-out predictions.\n",
    "- We generate a user ID and a left-out movie ID using left-out prediction.\n",
    "- Using this left-out movie ID, compare it with the movie ID and compute the hit and total.\n",
    "- Now, let's print the calculated HitRate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ihLxWtio8_kr"
   },
   "outputs": [],
   "source": [
    " def HitRate(topNPredicted, leftoutPredictions):\n",
    "        hits = 0\n",
    "        total =0\n",
    "        \n",
    "        for leftout in leftoutpredictions:\n",
    "            userid =  leftout[0]\n",
    "            leftoutmovieid = leftout[1]\n",
    "            \n",
    "            hit = False\n",
    "            for movieid, predictedRating in topNpredicted[int(userid)]:\n",
    "                if (int(leftoutmovieid)  == int(movieid)):\n",
    "                    hit = True\n",
    "                    break\n",
    "            if (hit) :\n",
    "                hits += 1\n",
    "            \n",
    "            total += 1\n",
    "            \n",
    "        return hits/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlPI632XeD_z"
   },
   "source": [
    "Now, let's check the HitRate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 400,
     "status": "ok",
     "timestamp": 1683517428885,
     "user": {
      "displayName": "Sreelakshmi C V",
      "userId": "04477517605899898333"
     },
     "user_tz": -330
    },
    "id": "7hrnuvfL8_kr",
    "outputId": "106157cf-8408-4ac4-dc27-8d5d87a66333"
   },
   "outputs": [],
   "source": [
    "print(\"\\nHit Rate : \", HitRate(topNpredicted, leftoutpredictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZGfUnVqTH-Jv"
   },
   "source": [
    "**Observation:**\n",
    "- The hit frequency is 0.0245."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
